{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "975fb24f",
   "metadata": {},
   "source": [
    "# Recipe Finder – Cuisine Classification\n",
    "### TF–IDF + Logistic Regression (Machine Learning Model)\n",
    "\n",
    "This notebook trains a machine learning model that predicts the **cuisine type** from a list of ingredients.\n",
    "The trained model will later be used inside the Streamlit application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f84078",
   "metadata": {},
   "source": [
    "## 0. Setup\n",
    "Install dependencies, import libraries, and define paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a750f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, json, re, joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "DATA_DIR = PROJECT_ROOT / \"data\" / \"whats_cooking\"\n",
    "MODEL_DIR = PROJECT_ROOT / \"app\" / \"models\"\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"DATA_DIR exists?\", DATA_DIR.exists())\n",
    "print(\"MODEL_DIR:\", MODEL_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f280085f",
   "metadata": {},
   "source": [
    "## 1. Load Dataset\n",
    "Place `train.json` at `data/whats_cooking/train.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9493133a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_path = DATA_DIR / \"train.json\"\n",
    "assert train_path.exists(), f\"Missing {train_path}. Please download the Kaggle dataset.\"\n",
    "\n",
    "with open(train_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    rows = json.load(f)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "def normalize_ingredient(s: str) -> str:\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"[^a-z\\s]+\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "df[\"text\"] = df[\"ingredients\"].apply(lambda ingr: \" \".join(normalize_ingredient(x) for x in ingr))\n",
    "df = df[[\"text\", \"cuisine\"]].dropna()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35044669",
   "metadata": {},
   "source": [
    "## 2. Train–Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849be97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    df[\"text\"], df[\"cuisine\"], test_size=0.2, random_state=42, stratify=df[\"cuisine\"]\n",
    ")\n",
    "len(X_train), len(X_val), len(set(y_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6164ab",
   "metadata": {},
   "source": [
    "## 3. Train Model – TF‑IDF + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d003bc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(ngram_range=(1,2), min_df=2, max_features=150000)),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000))\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "pred = pipeline.predict(X_val)\n",
    "f1 = f1_score(y_val, pred, average=\"micro\")\n",
    "print(\"Validation micro-F1:\", round(f1, 4))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b15ff6",
   "metadata": {},
   "source": [
    "## 4. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f114742",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_path = MODEL_DIR / \"cuisine_pipeline.joblib\"\n",
    "joblib.dump(pipeline, model_path)\n",
    "model_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c4276e",
   "metadata": {},
   "source": [
    "## 5. Quick Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b425a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def classify_ingredients(ingredients):\n",
    "    text = \" \".join(normalize_ingredient(x) for x in ingredients)\n",
    "    clf = pipeline.named_steps[\"clf\"]\n",
    "    tfidf = pipeline.named_steps[\"tfidf\"]\n",
    "    X = tfidf.transform([text])\n",
    "    if hasattr(clf, \"predict_proba\"):\n",
    "        proba = clf.predict_proba(X)[0]\n",
    "        idx = int(proba.argmax())\n",
    "        return clf.classes_[idx], float(proba[idx])\n",
    "    else:\n",
    "        return pipeline.predict([text])[0], 1.0\n",
    "\n",
    "classify_ingredients([\"tomato\",\"basil\",\"olive oil\",\"parmesan\"])\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
