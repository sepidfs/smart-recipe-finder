{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mByq87Vz-X3"
      },
      "source": [
        "##RecipeFinder_ML_Notebook\n",
        "\n",
        "# Sepideh Forouzi\n",
        "\n",
        "#Introduction\n",
        "\n",
        "The purpose of this project is to develop Smart Recipe Finder (PRO), an intelligent culinary recommendation system designed to predict cuisine types and generate meaningful recipe insights based solely on user-provided ingredients. The motivation behind the project is to create a practical, data-driven tool that enables users to explore new cuisines, understand the nutritional value of their ingredients, and receive personalized recipe suggestions without requiring prior domain knowledge.\n",
        "\n",
        "The machine-learning foundation of the system is a pre-trained cuisine classification pipeline, stored in cuisine_pipeline.joblib. This model was originally trained using the Kaggle Recipe Ingredients Dataset:\n",
        "üîó https://www.kaggle.com/datasets/kaggle/recipe-ingredients-dataset\n",
        "\n",
        "This dataset is one of the largest publicly available culinary datasets, containing:\n",
        "\n",
        "over 2,000,000 individual ingredient entries, and\n",
        "\n",
        "approximately 45,000 fully structured recipes,\n",
        "spanning a wide range of global cuisines.\n",
        "\n",
        "Its scale and ingredient-focused structure make it especially suitable for training an ingredient-based cuisine classifier. The model used in this project employs TF‚ÄìIDF vectorization on ingredient lists combined with a linear classifier (Logistic Regression or Linear SVM), with label mappings stored in the accompanying labels.json file.\n",
        "\n",
        "In this project, I integrated this trained model into a comprehensive recipe-analysis workflow. I implemented ingredient preprocessing (Unicode normalization, regex cleaning, and deduplication), a strict vegetarian filtering module that removes non-vegetarian components and substitutes plant-based alternatives, and a prediction layer that produces Top-K cuisine probabilities. Additionally, I developed a nutritional estimation component that computes approximate calories, protein, fat, and carbohydrates from the refined ingredient list.\n",
        "\n",
        "To support interpretability and user engagement, I created multiple interactive Plotly visualizations, such as probability bar charts for cuisine predictions, calorie line charts, and stacked macronutrient plots. The full system is delivered through a Streamlit interface, enabling users to input ingredients, review predictions, inspect vegetarian adjustments, and explore nutritional summaries. A Jupyter-compatible visualization module was also added, allowing the same charts to be rendered directly inside a Notebook for transparent analysis and documentation.\n",
        "\n",
        "Overall, this project combines machine learning, text analysis, dietary constraints, and interactive visualization into a unified and practical application for ingredient-based culinary recommendation.\n"
      ],
      "id": "0mByq87Vz-X3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "imports_and_setup",
        "id": "hTmlM5igz-X4"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# =====================================================================\n",
        "# Smart Recipe Finder (PRO) ‚Äî Distinct Cards + Hard Ingredient Coverage\n",
        "# =====================================================================\n",
        "\n",
        "from __future__ import annotations\n",
        "import io, os, re, json, hashlib, random, time, unicodedata, uuid\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple, Dict, Optional\n",
        "\n",
        "import sklearn\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import streamlit as st\n",
        "import plotly.graph_objects as go\n",
        "import plotly.io as pio\n",
        "import requests\n",
        "import re\n",
        "import unicodedata\n",
        "\n"
      ],
      "id": "hTmlM5igz-X4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "_normalize_veg_dairy_terms",
        "id": "LEJv6CHpz-X5"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def _normalize_veg_dairy_terms(rec: dict) -> dict:\n",
        "    \"\"\"\n",
        "    Convert dairy/gelatin/ice-cream items to plant-based equivalents.\n",
        "    Safe for vegetarian mode only.\n",
        "    \"\"\"\n",
        "    if not rec:\n",
        "        return rec\n",
        "\n",
        "    # Patterns to replace\n",
        "    replacements = [\n",
        "        (r\"\\bmilk\\b\",       \"soy milk\"),\n",
        "        (r\"\\byogurt\\b\",     \"soy yogurt\"),\n",
        "        (r\"\\bbutter\\b\",     \"soy butter\"),\n",
        "        (r\"\\bcheese\\b\",     \"soy cheese\"),\n",
        "        (r\"\\bcream\\b\",      \"soy cream\"),\n",
        "        (r\"\\bice\\s*cream\\b\",\"soy ice cream\"),\n",
        "        (r\"\\bgelatin(e)?\\b\",\"agar agar\"),\n",
        "    ]\n",
        "\n",
        "    def sub_all(text: str) -> str:\n",
        "        t = text.lower()\n",
        "        for pat, rep in replacements:\n",
        "            t = re.sub(pat, rep, t, flags=re.IGNORECASE)\n",
        "        return t\n",
        "\n",
        "    new = dict(rec)\n",
        "\n",
        "    # ingredients\n",
        "    new_ings = []\n",
        "    for ing in rec.get(\"ingredients\", []):\n",
        "        new_ings.append(sub_all(str(ing)))\n",
        "    new[\"ingredients\"] = new_ings\n",
        "\n",
        "    # steps\n",
        "    steps = rec.get(\"steps\", [])\n",
        "    if isinstance(steps, list):\n",
        "        new[\"steps\"] = [sub_all(str(s)) for s in steps]\n",
        "    else:\n",
        "        new[\"steps\"] = sub_all(str(steps))\n",
        "\n",
        "    # title\n",
        "    new[\"title\"] = sub_all(rec.get(\"title\",\"\"))\n",
        "\n",
        "    return new\n",
        "\n",
        "\n",
        "# --------------------------- Optional stacks ---------------------------\n",
        "PDF_OK = True; TRANS_OK = True; TTS_OK = True; KALEIDO_OK = True\n"
      ],
      "id": "LEJv6CHpz-X5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "_probe_optional",
        "id": "5N7alzUmz-X5"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def _probe_optional():\n",
        "    global PDF_OK, TRANS_OK, TTS_OK, KALEIDO_OK\n",
        "    try: import reportlab                    # noqa: F401\n",
        "    except Exception: PDF_OK = False\n",
        "    try: from deep_translator import GoogleTranslator  # noqa: F401\n",
        "    except Exception: TRANS_OK = False\n",
        "    try: import gtts, pydub                 # noqa: F401\n",
        "    except Exception: TTS_OK = False\n",
        "    try: _ = pio.kaleido.scope\n",
        "    except Exception: KALEIDO_OK = False\n",
        "_probe_optional()\n",
        "PDF_OK = True; TRANS_OK = True; TTS_OK = True; KALEIDO_OK = True\n"
      ],
      "id": "5N7alzUmz-X5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "_probe_optional",
        "id": "cMTQ7J6vz-X5"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def _probe_optional():\n",
        "    global PDF_OK, TRANS_OK, TTS_OK, KALEIDO_OK\n",
        "    try: import reportlab                    # noqa: F401\n",
        "    except Exception: PDF_OK = False\n",
        "    try: from deep_translator import GoogleTranslator  # noqa: F401\n",
        "    except Exception: TRANS_OK = False\n",
        "    try: import gtts, pydub                 # noqa: F401\n",
        "    except Exception: TTS_OK = False\n",
        "    try: _ = pio.kaleido.scope\n",
        "    except Exception: KALEIDO_OK = False\n",
        "\n",
        "_probe_optional()\n",
        "\n",
        "# ---- Localized labels for PDFs (en/fr/de) ----\n",
        "_PDF_I18N = {\n",
        "    \"en\": {\n",
        "        \"ingredients\": \"Ingredients:\",\n",
        "        \"instructions\": \"Instructions:\",\n",
        "        \"nutrition\": \"Nutrition (approx.):\",\n",
        "        \"kcal\": \"Calories (kcal)\",\n",
        "        \"protein\": \"Protein (g)\",\n",
        "        \"fat\": \"Fat (g)\",\n",
        "        \"carbs\": \"Carbs (g)\",\n",
        "        \"podcast_title_suffix\": \"‚Äî Podcast Transcript\",\n",
        "    },\n",
        "    \"fr\": {\n",
        "        \"ingredients\": \"Ingr√©dients :\",\n",
        "        \"instructions\": \"Instructions :\",\n",
        "        \"nutrition\": \"Valeurs nutritionnelles (approx.) :\",\n",
        "        \"kcal\": \"Calories (kcal)\",\n",
        "        \"protein\": \"Prot√©ines (g)\",\n",
        "        \"fat\": \"Lipides (g)\",\n",
        "        \"carbs\": \"Glucides (g)\",\n",
        "        \"podcast_title_suffix\": \"‚Äî Transcription du podcast\",\n",
        "    },\n",
        "    \"de\": {\n",
        "        \"ingredients\": \"Zutaten:\",\n",
        "        \"instructions\": \"Anleitung:\",\n",
        "        \"nutrition\": \"N√§hrwerte (ca.):\",\n",
        "        \"kcal\": \"Kalorien (kcal)\",\n",
        "        \"protein\": \"Eiwei√ü (g)\",\n",
        "        \"fat\": \"Fett (g)\",\n",
        "        \"carbs\": \"Kohlenhydrate (g)\",\n",
        "        \"podcast_title_suffix\": \"‚Äî Podcast-Transkript\",\n",
        "    },\n",
        "}\n"
      ],
      "id": "cMTQ7J6vz-X5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "_lbl",
        "id": "l9FKwsqdz-X6"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def _lbl(lang: str, key: str) -> str:\n",
        "    d = _PDF_I18N.get(lang or \"en\", _PDF_I18N[\"en\"])\n",
        "    return d.get(key, _PDF_I18N[\"en\"].get(key, key))\n",
        "\n",
        "\n",
        "# --------------------------- Secrets helper ---------------------------\n"
      ],
      "id": "l9FKwsqdz-X6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "_get_env_or_secret",
        "id": "91FLfzQcz-X6"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def _get_env_or_secret(name: str) -> str:\n",
        "    val = os.environ.get(name, \"\")\n",
        "    if val: return val.strip()\n",
        "    try: return str(st.secrets[name]).strip()\n",
        "    except Exception: return \"\"\n",
        "\n",
        "# ------------------------------ Paths ---------------------------------\n",
        "APP_DIR     = Path(__file__).resolve().parent\n",
        "ASSETS_DIR  = APP_DIR / \"assets\"\n",
        "LOGO_PATH   = ASSETS_DIR / \"logo_srf.png\"\n",
        "ICON_VEG    = ASSETS_DIR / \"veg.png\"\n",
        "ICON_NONV   = ASSETS_DIR / \"nonveg.png\"\n",
        "\n",
        "MODEL_PATHS = [\n",
        "    APP_DIR / \"cuisine_pipeline.joblib\",\n",
        "    APP_DIR / \"models\" / \"cuisine_pipeline.joblib\",\n",
        "    Path(\"/mnt/data\") / \"cuisine_pipeline.joblib\",\n",
        "]\n",
        "LABEL_PATHS = [\n",
        "    APP_DIR / \"labels.json\",\n",
        "    APP_DIR / \"models\" / \"labels.json\",\n",
        "    Path(\"/mnt/data\") / \"labels.json\",\n",
        "]\n",
        "\n",
        "# placeholders used only if image APIs fail; lock seeded by hash(title+salt)\n",
        "IMG_VEG_FALLBACK = \"vegetarian,kebab,grill,dish\"\n",
        "IMG_NON_FALLBACK = \"bbq,kebab,grill,meal\"\n",
        "\n",
        "TITLE = \"Smart Recipe Finder (PRO)\"\n",
        "TOPK  = 3\n",
        "np.random.seed(42)\n",
        "\n",
        "LANGUAGE_CHOICES = {\"English\":\"en\",\"French\":\"fr\",\"German\":\"de\"}\n",
        "\n",
        "st.set_page_config(page_title=TITLE, page_icon=\"üçΩÔ∏è\", layout=\"wide\")\n",
        "st.markdown(\n",
        "    \"\"\"\n",
        "    <style>\n",
        "    div.stButton > button[kind=\"primary\"]{background:#dc2626;border-color:#dc2626}\n",
        "    [data-testid=\"stExpander\"] details summary{font-weight:600}\n",
        "    .card {border-radius:10px;background:#0b0f14;padding:10px;margin-bottom:8px}\n",
        "    .pill {background:#065f46;color:white;padding:6px 10px;border-radius:8px;display:inline-block}\n",
        "    .caption {font-size:0.78rem;opacity:0.65}\n",
        "    .howto li {margin-bottom:4px;}\n",
        "    </style>\n",
        "    \"\"\",\n",
        "    unsafe_allow_html=True\n",
        ")\n",
        "\n",
        "if LOGO_PATH.exists():\n",
        "    _, c2, _ = st.columns([1,2,1])\n",
        "    with c2: st.image(str(LOGO_PATH), width=240)\n",
        "\n",
        "# --------------------------- Session defaults --------------------------\n",
        "for k, v in {\n",
        "    \"meal_plan\": [], \"pred_ready\": False, \"ings\": [], \"df_pred\": pd.DataFrame(),\n",
        "    \"cuisines\": [], \"meta\": {}, \"selected\": None, \"last_sig\": \"\",\n",
        "    \"recs_top3\": [], \"diet\": \"Non-vegetarian\", \"podcast_context\": {},\n",
        "    \"veg_dropped\": set(), \"title_to_ings\": {}, \"search_salt\":\"\"\n",
        "}.items(): st.session_state.setdefault(k, v)\n",
        "\n",
        "# --------------------------- Nutrition (toy) ---------------------------\n",
        "# --------------------------- Nutrition (toy) ---------------------------\n",
        "# Canonical nutrition + rich alias coverage (all per 100g)\n",
        "NUTR_TABLE = {\n",
        "    # --- Chicken & Poultry ---\n",
        "    \"chicken\":               {\"kcal\":165,\"protein\":31.0,\"fat\":3.6,\"carbs\":0.0},\n",
        "    \"chicken breast\":        {\"kcal\":165,\"protein\":31.0,\"fat\":3.6,\"carbs\":0.0},\n",
        "    \"boneless chicken\":      {\"kcal\":165,\"protein\":31.0,\"fat\":3.6,\"carbs\":0.0},\n",
        "    \"chicken fillet\":        {\"kcal\":165,\"protein\":31.0,\"fat\":3.6,\"carbs\":0.0},\n",
        "    \"chicken thighs\":        {\"kcal\":209,\"protein\":26.0,\"fat\":10.9,\"carbs\":0.0},\n",
        "    \"chicken thigh\":         {\"kcal\":209,\"protein\":26.0,\"fat\":10.9,\"carbs\":0.0},\n",
        "    \"chicken drumstick\":     {\"kcal\":161,\"protein\":18.0,\"fat\":9.2,\"carbs\":0.0},\n",
        "    \"drumstick\":             {\"kcal\":161,\"protein\":18.0,\"fat\":9.2,\"carbs\":0.0},\n",
        "    \"chicken wing\":          {\"kcal\":203,\"protein\":30.5,\"fat\":8.1,\"carbs\":0.0},\n",
        "    \"wings\":                 {\"kcal\":203,\"protein\":30.5,\"fat\":8.1,\"carbs\":0.0},\n",
        "    \"ground chicken\":        {\"kcal\":189,\"protein\":23.0,\"fat\":10.0,\"carbs\":0.0},\n",
        "\n",
        "    \"turkey\":                {\"kcal\":135,\"protein\":29.0,\"fat\":1.0,\"carbs\":0.0},\n",
        "    \"turkey breast\":         {\"kcal\":135,\"protein\":29.0,\"fat\":1.0,\"carbs\":0.0},\n",
        "    \"ground turkey\":         {\"kcal\":209,\"protein\":27.0,\"fat\":10.0,\"carbs\":0.0},\n",
        "\n",
        "    \"duck\":                  {\"kcal\":337,\"protein\":19.0,\"fat\":28.0,\"carbs\":0.0},\n",
        "    \"duck breast\":           {\"kcal\":337,\"protein\":19.0,\"fat\":28.0,\"carbs\":0.0},\n",
        "    \"goose\":                 {\"kcal\":305,\"protein\":25.0,\"fat\":22.0,\"carbs\":0.0},\n",
        "\n",
        "    # --- Beef ---\n",
        "    \"beef\":                  {\"kcal\":217,\"protein\":26.1,\"fat\":11.8,\"carbs\":0.0},\n",
        "    \"ground beef\":           {\"kcal\":254,\"protein\":26.0,\"fat\":15.0,\"carbs\":0.0},\n",
        "    \"minced beef\":           {\"kcal\":254,\"protein\":26.0,\"fat\":15.0,\"carbs\":0.0},\n",
        "    \"beef mince\":            {\"kcal\":254,\"protein\":26.0,\"fat\":15.0,\"carbs\":0.0},\n",
        "    \"sirloin\":               {\"kcal\":206,\"protein\":28.0,\"fat\":10.0,\"carbs\":0.0},\n",
        "    \"ribeye\":                {\"kcal\":291,\"protein\":24.0,\"fat\":21.0,\"carbs\":0.0},\n",
        "    \"steak\":                 {\"kcal\":217,\"protein\":26.1,\"fat\":11.8,\"carbs\":0.0},\n",
        "\n",
        "    # --- Lamb / Goat / Game ---\n",
        "    \"lamb\":                  {\"kcal\":294,\"protein\":25.0,\"fat\":21.0,\"carbs\":0.0},\n",
        "    \"ground lamb\":           {\"kcal\":294,\"protein\":25.0,\"fat\":21.0,\"carbs\":0.0},\n",
        "    \"minced lamb\":           {\"kcal\":294,\"protein\":25.0,\"fat\":21.0,\"carbs\":0.0},\n",
        "    \"goat\":                  {\"kcal\":143,\"protein\":27.0,\"fat\":3.0,\"carbs\":0.0},\n",
        "    \"venison\":               {\"kcal\":158,\"protein\":30.0,\"fat\":3.2,\"carbs\":0.0},\n",
        "\n",
        "    # --- Pork ---\n",
        "    \"pork\":                  {\"kcal\":242,\"protein\":27.0,\"fat\":14.0,\"carbs\":0.0},\n",
        "    \"pork loin\":             {\"kcal\":242,\"protein\":27.0,\"fat\":14.0,\"carbs\":0.0},\n",
        "    \"pork chop\":             {\"kcal\":242,\"protein\":27.0,\"fat\":14.0,\"carbs\":0.0},\n",
        "    \"pork tenderloin\":       {\"kcal\":143,\"protein\":26.0,\"fat\":3.5,\"carbs\":0.0},\n",
        "    \"pork belly\":            {\"kcal\":518,\"protein\":9.3,\"fat\":53.0,\"carbs\":0.0},\n",
        "    \"pork sausage\":          {\"kcal\":301,\"protein\":12.0,\"fat\":27.0,\"carbs\":1.0},\n",
        "    \"bacon\":                 {\"kcal\":541,\"protein\":37.0,\"fat\":42.0,\"carbs\":1.4},\n",
        "\n",
        "    # --- Processed ---\n",
        "    \"ham\":                   {\"kcal\":145,\"protein\":20.9,\"fat\":5.5,\"carbs\":1.5},\n",
        "    \"salami\":                {\"kcal\":336,\"protein\":22.0,\"fat\":26.0,\"carbs\":1.5},\n",
        "\n",
        "    # --- Seafood & Aliases ---\n",
        "    \"whitefish\":             {\"kcal\":96,\"protein\":20.0,\"fat\":1.5,\"carbs\":0.0},\n",
        "    \"fish\":                  {\"kcal\":96,\"protein\":20.0,\"fat\":1.5,\"carbs\":0.0},\n",
        "    \"seafood\":               {\"kcal\":96,\"protein\":20.0,\"fat\":1.5,\"carbs\":0.0},\n",
        "\n",
        "    \"salmon\":                {\"kcal\":208,\"protein\":20.4,\"fat\":13.0,\"carbs\":0.0},\n",
        "    \"salmon fillet\":         {\"kcal\":208,\"protein\":20.4,\"fat\":13.0,\"carbs\":0.0},\n",
        "\n",
        "    \"cod\":                   {\"kcal\":82,\"protein\":18.0,\"fat\":0.7,\"carbs\":0.0},\n",
        "    \"haddock\":               {\"kcal\":90,\"protein\":19.9,\"fat\":0.6,\"carbs\":0.0},\n",
        "    \"trout\":                 {\"kcal\":190,\"protein\":26.0,\"fat\":8.0,\"carbs\":0.0},\n",
        "    \"tilapia\":               {\"kcal\":129,\"protein\":26.1,\"fat\":2.7,\"carbs\":0.0},\n",
        "    \"tuna\":                  {\"kcal\":132,\"protein\":29.0,\"fat\":1.0,\"carbs\":0.0},\n",
        "    \"canned tuna\":           {\"kcal\":132,\"protein\":29.0,\"fat\":1.0,\"carbs\":0.0},\n",
        "    \"mackerel\":              {\"kcal\":205,\"protein\":18.6,\"fat\":13.9,\"carbs\":0.0},\n",
        "    \"sardine\":               {\"kcal\":208,\"protein\":24.6,\"fat\":11.5,\"carbs\":0.0},\n",
        "    \"anchovy\":               {\"kcal\":210,\"protein\":29.0,\"fat\":10.0,\"carbs\":0.0},\n",
        "\n",
        "    \"shrimp\":                {\"kcal\":99,\"protein\":24.0,\"fat\":0.3,\"carbs\":0.2},\n",
        "    \"prawn\":                 {\"kcal\":99,\"protein\":24.0,\"fat\":0.3,\"carbs\":0.2},\n",
        "    \"scallop\":               {\"kcal\":88,\"protein\":16.8,\"fat\":0.8,\"carbs\":3.2},\n",
        "    \"squid\":                 {\"kcal\":92,\"protein\":15.6,\"fat\":1.4,\"carbs\":3.1},\n",
        "    \"octopus\":               {\"kcal\":82,\"protein\":14.9,\"fat\":1.0,\"carbs\":2.2},\n",
        "    \"clam\":                  {\"kcal\":86,\"protein\":14.7,\"fat\":0.9,\"carbs\":3.6},\n",
        "    \"mussel\":                {\"kcal\":172,\"protein\":24.0,\"fat\":4.5,\"carbs\":7.4},\n",
        "    \"crab\":                  {\"kcal\":97,\"protein\":21.0,\"fat\":1.5,\"carbs\":0.0},\n",
        "    \"lobster\":               {\"kcal\":89,\"protein\":19.0,\"fat\":1.0,\"carbs\":0.0},\n",
        "\n",
        "    # --- Soy / Legumes ---\n",
        "    \"tofu\":                  {\"kcal\":76,\"protein\":8.0,\"fat\":4.8,\"carbs\":1.9},\n",
        "    \"lentil\":                {\"kcal\":116,\"protein\":9.0,\"fat\":0.4,\"carbs\":20.1},\n",
        "    \"bean\":                  {\"kcal\":127,\"protein\":8.7,\"fat\":0.5,\"carbs\":22.8},\n",
        "    \"chickpea\":              {\"kcal\":164,\"protein\":8.9,\"fat\":2.6,\"carbs\":27.4},\n",
        "\n",
        "    # --- Mushrooms (full alias set) ---\n",
        "    \"mushroom\":              {\"kcal\":22,\"protein\":3.1,\"fat\":0.3,\"carbs\":3.3},\n",
        "    \"button mushroom\":       {\"kcal\":22,\"protein\":3.1,\"fat\":0.3,\"carbs\":3.3},\n",
        "    \"cremini\":               {\"kcal\":22,\"protein\":3.1,\"fat\":0.3,\"carbs\":3.3},\n",
        "    \"portobello\":            {\"kcal\":22,\"protein\":3.1,\"fat\":0.3,\"carbs\":3.3},\n",
        "    \"shiitake\":              {\"kcal\":34,\"protein\":2.2,\"fat\":0.5,\"carbs\":6.8},\n",
        "    \"oyster mushroom\":       {\"kcal\":33,\"protein\":3.3,\"fat\":0.4,\"carbs\":6.1},\n",
        "    \"king oyster\":           {\"kcal\":35,\"protein\":3.5,\"fat\":0.3,\"carbs\":6.2},\n",
        "    \"enoki\":                 {\"kcal\":37,\"protein\":2.7,\"fat\":0.3,\"carbs\":7.8},\n",
        "    \"maitake\":               {\"kcal\":31,\"protein\":1.9,\"fat\":0.2,\"carbs\":6.9},\n",
        "    \"chanterelle\":           {\"kcal\":38,\"protein\":1.5,\"fat\":0.5,\"carbs\":6.9},\n",
        "    \"porcini\":               {\"kcal\":26,\"protein\":3.1,\"fat\":0.1,\"carbs\":4.6},\n",
        "    \"morel\":                 {\"kcal\":31,\"protein\":3.1,\"fat\":0.6,\"carbs\":5.1},\n",
        "\n",
        "    # --- Oils & Staples ---\n",
        "    \"olive oil\":             {\"kcal\":884,\"protein\":0.0,\"fat\":100.0,\"carbs\":0.0},\n",
        "    \"sesame oil\":            {\"kcal\":884,\"protein\":0.0,\"fat\":100.0,\"carbs\":0.0},\n",
        "    \"butter\":                {\"kcal\":717,\"protein\":0.9,\"fat\":81.1,\"carbs\":0.1},\n",
        "    \"soy sauce\":             {\"kcal\":53,\"protein\":8.0,\"fat\":0.6,\"carbs\":5.6},\n",
        "    \"rice\":                  {\"kcal\":130,\"protein\":2.4,\"fat\":0.3,\"carbs\":28.0},\n",
        "    \"pasta\":                 {\"kcal\":131,\"protein\":5.0,\"fat\":1.1,\"carbs\":25.0},\n",
        "\n",
        "    # --- Vegetables & Herbs ---\n",
        "    \"garlic\":                {\"kcal\":149,\"protein\":6.4,\"fat\":0.5,\"carbs\":33.1},\n",
        "    \"ginger\":                {\"kcal\":80,\"protein\":1.8,\"fat\":0.8,\"carbs\":17.8},\n",
        "    \"onion\":                 {\"kcal\":40,\"protein\":1.1,\"fat\":0.1,\"carbs\":9.3},\n",
        "    \"tomato\":                {\"kcal\":18,\"protein\":0.9,\"fat\":0.2,\"carbs\":3.9},\n",
        "    \"cherry tomatoes\":       {\"kcal\":18,\"protein\":0.9,\"fat\":0.2,\"carbs\":3.9},\n",
        "    \"basil\":                 {\"kcal\":23,\"protein\":3.2,\"fat\":0.6,\"carbs\":2.7},\n",
        "    \"spinach\":               {\"kcal\":23,\"protein\":2.9,\"fat\":0.4,\"carbs\":3.6},\n",
        "    \"broccoli\":              {\"kcal\":34,\"protein\":2.8,\"fat\":0.4,\"carbs\":6.6}\n",
        "}\n",
        "\n",
        "\n",
        "# ------------------------------ Model ---------------------------------\n"
      ],
      "id": "91FLfzQcz-X6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "_first_existing",
        "id": "BgoFjxFlz-X6"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def _first_existing(paths: List[Path]) -> Optional[Path]:\n",
        "    for p in paths:\n",
        "        if p.exists(): return p\n",
        "    return None\n"
      ],
      "id": "BgoFjxFlz-X6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "block",
        "id": "1ikk1JMxz-X6"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "@st.cache_resource(show_spinner=\"Loading cuisine model‚Ä¶\")\n",
        "def load_pipeline():\n",
        "    mp = _first_existing(MODEL_PATHS)\n",
        "    lp = _first_existing(LABEL_PATHS)\n",
        "    if mp is None: st.error(\"Missing model file: cuisine_pipeline.joblib\"); st.stop()\n",
        "    if lp is None: st.error(\"Missing labels file: labels.json\"); st.stop()\n",
        "    pipe = joblib.load(mp)\n",
        "    raw  = json.loads(lp.read_text(encoding=\"utf-8\"))\n",
        "    inv  = {i:n for i,n in enumerate(raw)} if isinstance(raw, list) else {int(k):v for k,v in raw.items()}\n",
        "    return pipe, inv\n",
        "\n",
        "pipe, INV = load_pipeline()\n",
        "\n",
        "# ------------------------------ Helpers -------------------------------\n",
        "# ============================================================\n",
        "# ============================================================\n",
        "# Strict Non-Vegetarian tokens (used by _near_nonveg / veg gate)\n",
        "# Eggs & gelatin included (strict-veg per your UI description)\n",
        "# ============================================================\n",
        "NONVEG = {\n",
        "    # generic\n",
        "    \"meat\",\"seafood\",\n",
        "\n",
        "    # poultry & livestock\n",
        "    \"chicken\",\"beef\",\"pork\",\"lamb\",\"mutton\",\"turkey\",\"duck\",\"veal\",\"goat\",\n",
        "\n",
        "    # game meats\n",
        "    \"venison\",\"boar\",\"rabbit\",\"kangaroo\",\n",
        "\n",
        "    # processed & cured meats / fats\n",
        "    \"bacon\",\"ham\",\"prosciutto\",\"mortadella\",\"pastrami\",\"bresaola\",\"capicola\",\n",
        "    \"pepperoni\",\"salami\",\"chorizo\",\"sausage\",\"frankfurter\",\"hotdog\",\"lard\",\n",
        "\n",
        "    # organ meats\n",
        "    \"liver\",\"kidney\",\"tripe\",\"sweetbread\",\"offal\",\"liverwurst\",\n",
        "\n",
        "    # fish (broad coverage)\n",
        "    \"fish\",\"salmon\",\"tuna\",\"cod\",\"haddock\",\"pollock\",\"tilapia\",\"catfish\",\"herring\",\n",
        "    \"anchovy\",\"sardine\",\"mackerel\",\"trout\",\"bass\",\"snapper\",\"swordfish\",\"shark\",\"eel\",\n",
        "\n",
        "    # cephalopods & molluscs\n",
        "    \"squid\",\"calamari\",\"octopus\",\"cuttlefish\",\"oyster\",\"clam\",\"mussel\",\"scallop\",\n",
        "\n",
        "    # crustaceans\n",
        "    \"shrimp\",\"prawn\",\"crab\",\"lobster\",\"krill\",\n",
        "\n",
        "    # eggs & gelatin (strict vegetarian excludes these)\n",
        "    \"egg\",\"eggs\",\"yolk\",\"gelatin\",\"gelatine\"\n",
        "}\n",
        "\n",
        "# ============================================================\n",
        "# Common spelling mistakes / alias correction (lowercase keys)\n",
        "# (Used by _canon_token before NONVEG checks)\n",
        "# ============================================================\n",
        "NONVEG_ALIASES = {\n",
        "    # poultry / livestock misspellings\n",
        "    \"chiken\":\"chicken\",\"chikn\":\"chicken\",\"chk\":\"chicken\",\"ckn\":\"chicken\",\n",
        "    \"beaf\":\"beef\",\"biff\":\"beef\",\"porc\":\"pork\",\"porco\":\"pork\",\"lam\":\"lamb\",\n",
        "    \"mouton\":\"mutton\",\"turky\":\"turkey\",\"duk\":\"duck\",\"goatte\":\"goat\",\n",
        "\n",
        "    # processed meats\n",
        "    \"becon\":\"bacon\",\"bacn\":\"bacon\",\"jamon\":\"ham\",\"prosciuto\":\"prosciutto\",\n",
        "    \"pepperonni\":\"pepperoni\",\"peperoni\":\"pepperoni\",\"salame\":\"salami\",\n",
        "    \"saussage\":\"sausage\",\"sossage\":\"sausage\",\"chorizzo\":\"chorizo\",\n",
        "    \"frankfurter\":\"frankfurter\",\"hot dog\":\"hotdog\",\"hot-dog\":\"hotdog\",\n",
        "\n",
        "    # fish & seafood misspellings/aliases\n",
        "    \"fishes\":\"fish\",\"tuna fish\":\"tuna\",\"salomon\":\"salmon\",\"salamon\":\"salmon\",\n",
        "    \"mackarel\":\"mackerel\",\"anchovi\":\"anchovy\",\"anchovey\":\"anchovy\",\n",
        "    \"sardin\":\"sardine\",\"sardines\":\"sardine\",\"codfish\":\"cod\",\n",
        "    \"basa\":\"catfish\",  # common market name mapping (optional)\n",
        "    \"calamary\":\"calamari\",\"sqiud\":\"squid\",\"octopuss\":\"octopus\",\n",
        "    \"prawns\":\"prawn\",\"shrimpes\":\"shrimp\",\"shrimps\":\"shrimp\",\n",
        "\n",
        "    # organ/offal\n",
        "    \"foie\":\"liver\",\"foiegras\":\"liver\",\"sweetbreads\":\"sweetbread\",\n",
        "\n",
        "    # eggs & gelatin\n",
        "    \"eg\":\"egg\",\"yolks\":\"yolk\",\"gelatine\":\"gelatin\",\n",
        "\n",
        "    # plurals to base\n",
        "    \"meats\":\"meat\",\"beefs\":\"beef\",\"chickens\":\"chicken\",\"fishes\":\"fish\",\n",
        "    \"sausages\":\"sausage\",\"bacons\":\"bacon\",\"hams\":\"ham\",\"salamis\":\"salami\",\n",
        "    \"pepperonis\":\"pepperoni\",\"prawns\":\"prawn\",\"shrimps\":\"shrimp\",\n",
        "    \"lobsters\":\"lobster\",\"crabs\":\"crab\",\"oysters\":\"oyster\",\"clams\":\"clam\",\n",
        "    \"mussels\":\"mussel\",\"scallops\":\"scallop\",\"eggs\":\"egg\"\n",
        "}\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Non-veg phrases (sauces, stocks, pastes, broths)\n",
        "# Dairy & eggs are intentionally NOT here.\n",
        "# ============================================================\n",
        "_NONVEG_PHRASES = [\n",
        "    \"fish sauce\", \"oyster sauce\", \"shrimp paste\", \"bonito\", \"nam pla\", \"dashi\",\n",
        "    \"chicken stock\", \"beef stock\", \"fish stock\", \"bone broth\",\n",
        "]\n",
        "\n",
        "# --- Vegetarian substitutions ---\n",
        "_VEG_SUBS = {\n",
        "    r\"\\bmilk\\b\": [\"soy milk\", \"almond milk\", \"oat milk\"],\n",
        "    r\"\\byogurt\\b\": [\"soy yogurt\", \"coconut yogurt\", \"almond yogurt\"],\n",
        "    r\"\\bbutter\\b\": [\"soy butter\", \"olive oil\", \"vegan butter\"],\n",
        "    r\"\\bcheese\\b\": [\"soy cheese\", \"plant-based cheese\", \"nut parmesan\"],\n",
        "    r\"\\bcream\\b\": [\"soy cream\", \"coconut cream\", \"cashew cream\"],\n",
        "    r\"\\bfish sauce\\b\": [\"soy sauce + lime\", \"mushroom soy\"],\n",
        "    r\"\\bchicken stock\\b\": [\"vegetable stock\"],\n",
        "    r\"\\bbeef stock\\b\": [\"vegetable stock\"],\n",
        "    r\"\\bfish stock\\b\": [\"vegetable stock\"],\n",
        "    r\"\\begg\\b|\\beggs\\b|\\byolk\\b|\\byolks\\b\": [\"flax egg\", \"chia egg\"],\n",
        "    r\"\\bchicken\\b\": [\"firm tofu\", \"seitan\"],\n",
        "    r\"\\bbeef\\b\": [\"mushroom mince\", \"textured soy\"],\n",
        "    r\"\\bpork\\b\": [\"tempeh\"],\n",
        "    r\"\\blamb\\b|\\bmutton\\b\": [\"seitan\"],\n",
        "    r\"\\bfish\\b|\\bsalmon\\b|\\btuna\\b|\\bcod\\b\": [\"tofu (pressed)\", \"king oyster mushroom\"],\n",
        "    r\"\\bshrimp\\b|\\bprawn\\b|\\bcrab\\b\": [\"king oyster mushroom slices\"],\n",
        "}\n",
        "\n",
        "_DAIRY_REQ = {\"milk\", \"yogurt\", \"butter\", \"cheese\", \"cream\"}\n"
      ],
      "id": "1ikk1JMxz-X6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "_rng_choice_deterministic",
        "id": "Ua9OqKuqz-X7"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def _rng_choice_deterministic(options: list[str], salt: str) -> str:\n",
        "    if not options: return \"\"\n",
        "    h = int(hashlib.sha1((\"subs|\" + salt).encode(\"utf-8\")).hexdigest(), 16)\n",
        "    return options[h % len(options)]\n"
      ],
      "id": "Ua9OqKuqz-X7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "_apply_veg_substitutions_text",
        "id": "YzUE7Vcjz-X7"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def _apply_veg_substitutions_text(text: str, salt: str) -> str:\n",
        "    out = text\n",
        "    for pat, opts in _VEG_SUBS.items():\n",
        "        repl = _rng_choice_deterministic(opts, salt)\n",
        "        out = re.sub(pat, repl, out, flags=re.IGNORECASE)\n",
        "    return out\n"
      ],
      "id": "YzUE7Vcjz-X7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "_apply_veg_substitutions_list",
        "id": "XqVqr5cIz-X7"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def _apply_veg_substitutions_list(items: list[str], salt: str) -> list[str]:\n",
        "    return [_apply_veg_substitutions_text(str(x), salt) for x in items]\n"
      ],
      "id": "XqVqr5cIz-X7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "_apply_veg_substitutions_recipe",
        "id": "uDCVL7yHz-X7"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def _apply_veg_substitutions_recipe(rec: dict, salt: str) -> dict:\n",
        "    \"\"\"Apply vegetarian-friendly substitutions to a whole recipe object.\"\"\"\n",
        "    r = dict(rec)\n",
        "    r[\"ingredients\"] = _apply_veg_substitutions_list(r.get(\"ingredients\", []), salt)\n",
        "    steps = r.get(\"steps\", [])\n",
        "    if isinstance(steps, list):\n",
        "        r[\"steps\"] = [_apply_veg_substitutions_text(str(s), salt) for s in steps]\n",
        "    else:\n",
        "        r[\"steps\"] = _apply_veg_substitutions_text(str(steps), salt)\n",
        "    r[\"title\"] = _apply_veg_substitutions_text(r.get(\"title\", \"\"), salt)\n",
        "    return r\n"
      ],
      "id": "uDCVL7yHz-X7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "_lev1",
        "id": "RqNFnfGLz-X7"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def _lev1(a: str, b: str) -> int:\n",
        "    if a == b: return 0\n",
        "    if abs(len(a)-len(b)) > 1: return 2\n",
        "    if len(a) == len(b):\n",
        "        mism = sum(1 for x, y in zip(a, b) if x != y)\n",
        "        return 1 if mism == 1 else 2\n",
        "    if len(a) < len(b): a, b = b, a\n",
        "    for i in range(len(a)):\n",
        "        if a[:i] + a[i+1:] == b: return 1\n",
        "    return 2\n"
      ],
      "id": "RqNFnfGLz-X7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "_canon_token",
        "id": "ZGZir2dez-X7"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def _canon_token(t: str) -> str:\n",
        "    s = re.sub(r\"[^a-z0-9]\", \"\", t.lower())\n",
        "    if s in NONVEG_ALIASES: s = NONVEG_ALIASES[s]\n",
        "    if s.endswith(\"s\") and len(s) > 3: s = s[:-1]\n",
        "    return s\n"
      ],
      "id": "ZGZir2dez-X7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "_near_nonveg",
        "id": "ELYBMGOaz-X8"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def _near_nonveg(tok: str) -> bool:\n",
        "    c = _canon_token(tok)\n",
        "    if c in NONVEG: return True\n",
        "    for nv in NONVEG:\n",
        "        if _lev1(c, nv) <= 1: return True\n",
        "    return False\n"
      ],
      "id": "ELYBMGOaz-X8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "_norm",
        "id": "1da4K1WLz-X8"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def _norm(s: str) -> str:\n",
        "    s = unicodedata.normalize(\"NFKD\", str(s))\n",
        "    return re.sub(r\"[^a-z0-9\\s]\", \"\", s.lower()).strip()\n"
      ],
      "id": "1da4K1WLz-X8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "_tokset",
        "id": "XavSmd6qz-X8"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def _tokset(xs: list[str]) -> set[str]:\n",
        "    out = set()\n",
        "    for x in xs:\n",
        "        for t in re.sub(r\"[^a-z0-9\\s]\",\" \",str(x).lower()).split():\n",
        "            if len(t) >= 2:\n",
        "                out.add(_canon_token(t))\n",
        "    return out\n"
      ],
      "id": "XavSmd6qz-X8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "_best3",
        "id": "C-MfO1zaz-X8"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def _best3(xs: List[str]) -> str:\n",
        "    base = [i.strip() for i in xs if i.strip()][:3]\n",
        "    return \", \".join(base) if base else \"seasonal ingredients\"\n"
      ],
      "id": "C-MfO1zaz-X8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "predict_topk",
        "id": "Xbb9zMBoz-X8"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def predict_topk(pipe, inv_labels, ings: List[str], k: int = TOPK) -> Tuple[List[str], np.ndarray]:\n",
        "    txt = \" \".join(ings)\n",
        "    proba = pipe.predict_proba([txt])[0]\n",
        "    order = np.argsort(proba)[::-1]\n",
        "    names, values, seen = [], [], set()\n",
        "    for idx in order:\n",
        "        c = inv_labels[idx]\n",
        "        if c not in seen:\n",
        "            names.append(c); values.append(float(proba[idx])); seen.add(c)\n",
        "        if len(names) == k: break\n",
        "    return names, np.array(values, dtype=float)\n"
      ],
      "id": "Xbb9zMBoz-X8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "macro_totals",
        "id": "CsuRKUxXz-X8"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def macro_totals(items: List[str]) -> Dict[str, float]:\n",
        "    tot = {\"kcal\":0.0,\"protein\":0.0,\"fat\":0.0,\"carbs\":0.0}\n",
        "    for it in items:\n",
        "        s = it.lower()\n",
        "        for key, nt in NUTR_TABLE.items():\n",
        "            if key in s:\n",
        "                tot[\"kcal\"] += nt[\"kcal\"]; tot[\"protein\"] += nt[\"protein\"]\n",
        "                tot[\"fat\"]  += nt[\"fat\"];   tot[\"carbs\"]   += nt[\"carbs\"]\n",
        "                break\n",
        "    return tot\n"
      ],
      "id": "CsuRKUxXz-X8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "_canon_ings",
        "id": "PLJ2hTX7z-X8"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def _canon_ings(text: str) -> tuple[list[str], str]:\n",
        "    text = unicodedata.normalize(\"NFKC\", str(text))\n",
        "    tokens = re.split(r\"[,\\n;ÿõ]+\", text)\n",
        "    ings = [t.strip() for t in tokens if t and t.strip()]\n",
        "    sig = \",\".join(sorted([s.lower() for s in ings]))\n",
        "    return ings, sig\n"
      ],
      "id": "PLJ2hTX7z-X8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "_veg_milk_swap",
        "id": "ujDP5t4ez-X8"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def _veg_milk_swap(ings: list[str]) -> tuple[list[str], set[str]]:\n",
        "    \"\"\"\n",
        "    Vegetarian mode: drop non-plant dairy terms and inject soy equivalents once.\n",
        "    Handles milk, yogurt/yoghurt, butter, cheese, cream.\n",
        "    Returns (new_ings, swapped_originals_set).\n",
        "    \"\"\"\n",
        "    out: list[str] = []\n",
        "    swapped: set[str] = set()\n",
        "\n",
        "    DAIRY = (\"milk\", \"yogurt\", \"yoghurt\", \"butter\", \"cheese\", \"cream\")\n",
        "    PLANT = (\"soy\", \"soya\", \"almond\", \"oat\", \"coconut\", \"rice\", \"plant\", \"vegan\")\n",
        "\n",
        "    for it in ings:\n",
        "        low = it.strip().lower()\n",
        "        is_dairy = any(w in low for w in DAIRY)\n",
        "        is_plant = any(p in low for p in PLANT)\n",
        "        if is_dairy and not is_plant:\n",
        "            swapped.add(it.strip())   # remove animal-dairy item\n",
        "        else:\n",
        "            out.append(it)\n",
        "\n",
        "    # Inject soy- equivalents based on what user originally mentioned\n",
        "    blob = \" \".join(ings).lower()\n",
        "\n",
        "    def _ensure(term: str):\n",
        "        if not any(term in x.lower() for x in out):\n",
        "            out.append(term)\n",
        "\n",
        "    if \"milk\"   in blob: _ensure(\"soy milk\")\n",
        "    if \"yogurt\" in blob or \"yoghurt\" in blob: _ensure(\"soy yogurt\")\n",
        "    if \"butter\" in blob: _ensure(\"soy butter\")\n",
        "    if \"cheese\" in blob: _ensure(\"soy cheese\")\n",
        "    if \"cream\"  in blob: _ensure(\"soy cream\")\n",
        "\n",
        "    return out, swapped\n",
        "\n",
        "\n",
        "# ===== STRICT-VEG helpers & constants (drop-in) =======================\n",
        "\n",
        "_DAIRY_WORDS    = (\"milk\",\"yogurt\",\"yoghurt\",\"butter\",\"cheese\",\"cream\")\n",
        "_STOCK_PHRASES  = (\"chicken stock\",\"beef stock\",\"fish stock\",\"bone broth\")\n",
        "_PLANT_MARKERS  = (\"soy\",\"soya\",\"almond\",\"oat\",\"coconut\",\"rice\",\"plant\",\"vegan\")  # used for detection\n"
      ],
      "id": "ujDP5t4ez-X8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "_veg_dairy_swap",
        "id": "cl-SGx3uz-X8"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def _veg_dairy_swap(items: list[str]) -> tuple[list[str], set[str]]:\n",
        "    \"\"\"\n",
        "    Remove animal-dairy and animal-stocks if they're not already plant-based,\n",
        "    and inject canonical soy-... replacements (once). Returns (new_items, swapped_set).\n",
        "    \"\"\"\n",
        "    out, swapped = [], set()\n",
        "    for it in items:\n",
        "        low = it.lower()\n",
        "\n",
        "        # Is it a dairy term without a plant marker?\n",
        "        is_dairy    = any(w in low for w in _DAIRY_WORDS)\n",
        "        is_plantish = any(p in low for p in _PLANT_MARKERS)\n",
        "\n",
        "        # Is it an explicit non-veg stock/broth?\n",
        "        is_stock    = any(ph in low for ph in _STOCK_PHRASES)\n",
        "\n",
        "        if (is_dairy and not is_plantish) or is_stock:\n",
        "            swapped.add(it)\n",
        "        else:\n",
        "            out.append(it)\n",
        "\n",
        "    # Inject canonical soy-‚Ä¶ once, based on what appeared in the original blob\n",
        "    blob = \" \".join(items).lower()\n",
        "    inject = []\n",
        "    if \"milk\"   in blob and \"soy milk\"   not in (x.lower() for x in out): inject.append(\"soy milk\")\n",
        "    if (\"yogurt\" in blob or \"yoghurt\" in blob) and \"soy yogurt\" not in (x.lower() for x in out): inject.append(\"soy yogurt\")\n",
        "    if \"butter\" in blob and \"soy butter\" not in (x.lower() for x in out): inject.append(\"soy butter\")\n",
        "    if \"cheese\" in blob and \"soy cheese\" not in (x.lower() for x in out): inject.append(\"soy cheese\")\n",
        "    if \"cream\"  in blob and \"soy cream\"  not in (x.lower() for x in out): inject.append(\"soy cream\")\n",
        "\n",
        "    # Always replace animal stocks with vegetable stock\n",
        "    if any(ph in blob for ph in _STOCK_PHRASES) and \"vegetable stock\" not in (x.lower() for x in out):\n",
        "        inject.append(\"vegetable stock\")\n",
        "\n",
        "    for a in inject:\n",
        "        out.append(a)\n",
        "\n",
        "    return out, swapped\n"
      ],
      "id": "cl-SGx3uz-X8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "_veg_milk_swap_in_recipe",
        "id": "ZJigoND8z-X9"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def _veg_milk_swap_in_recipe(rec: dict) -> tuple[dict, set[str]]:\n",
        "    \"\"\"\n",
        "    Vegetarian mode post-filter on a single recipe dict:\n",
        "    - Remove animal dairy (milk, yogurt, butter, cheese, cream) unless already plant-based.\n",
        "    - Remove animal stocks (chicken/beef/fish stock, bone broth).\n",
        "    - Inject canonical replacements: soy milk/yogurt/butter/cheese/cream, vegetable stock.\n",
        "    \"\"\"\n",
        "    if not rec:\n",
        "        return rec, set()\n",
        "    ings = list(rec.get(\"ingredients\", []))\n",
        "    new_ings, swapped = _veg_dairy_swap(ings)\n",
        "    if swapped:\n",
        "        rec = dict(rec)\n",
        "        rec[\"ingredients\"] = new_ings\n",
        "    return rec, swapped\n"
      ],
      "id": "ZJigoND8z-X9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "_is_vegetarian",
        "id": "4nP1_Qtjz-X9"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def _is_vegetarian(ingredients: list[str]) -> bool:\n",
        "    \"\"\"\n",
        "    Reject if any token is (near) non-veg OR if any explicit non-veg phrase appears.\n",
        "    (Relies on global NONVEG, _NONVEG_PHRASES, _tokset, _near_nonveg.)\n",
        "    \"\"\"\n",
        "    tokens = _tokset(ingredients)\n",
        "    if any(_near_nonveg(t) for t in tokens):\n",
        "        return False\n",
        "    low = \" \".join(ingredients).lower()\n",
        "    if any(p in low for p in _NONVEG_PHRASES):\n",
        "        return False\n",
        "    # Also treat explicit animal stocks as non-veg\n",
        "    if any(ph in low for ph in _STOCK_PHRASES):\n",
        "        return False\n",
        "    return True\n"
      ],
      "id": "4nP1_Qtjz-X9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "_required_tokens_for_mode",
        "id": "yfiI6DGkz-X9"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def _required_tokens_for_mode(\n",
        "    user_ings: list[str],\n",
        "    vegetarian: bool\n",
        ") -> tuple[set[str], set[str], set[str]]:\n",
        "    \"\"\"\n",
        "    Build the set of required tokens from user input.\n",
        "    In vegetarian mode:\n",
        "      - Drop animal proteins, eggs, gelatin, and explicit animal stocks.\n",
        "      - Map dairy to 'soy + <word>' (milk‚Üísoy milk, cheese‚Üísoy cheese, cream‚Üísoy cream, ...)\n",
        "    Also returns:\n",
        "      - dropped: what got removed (for UI)\n",
        "      - requested_proteins: exact protein tokens user asked for (fish, chicken, beef, shrimp, ...)\n",
        "    \"\"\"\n",
        "    req, dropped = set(), set()\n",
        "    requested_proteins: set[str] = set()\n",
        "\n",
        "    for raw in user_ings:\n",
        "        low_raw = str(raw).lower().strip()\n",
        "\n",
        "        # tokenize text\n",
        "        for t in re.sub(r\"[^a-z0-9\\s]\", \" \", low_raw).split():\n",
        "            if len(t) < 2:\n",
        "                continue\n",
        "\n",
        "            c = _canon_token(t)\n",
        "\n",
        "            if vegetarian:\n",
        "                # --- drop animal stocks ---\n",
        "                if any(ph in low_raw for ph in _STOCK_PHRASES):\n",
        "                    dropped.add(raw.strip())\n",
        "                    req.update({\"vegetable\", \"stock\"})\n",
        "                    continue\n",
        "\n",
        "                # --- dairy ‚Üí soy + word ---\n",
        "                if any(w in low_raw for w in _DAIRY_WORDS):\n",
        "                    dropped.add(raw.strip())\n",
        "                    if \"milk\"   in low_raw: req.update({\"soy\", \"milk\"})\n",
        "                    if \"yogurt\" in low_raw or \"yoghurt\" in low_raw: req.update({\"soy\", \"yogurt\"})\n",
        "                    if \"butter\" in low_raw: req.update({\"soy\", \"butter\"})\n",
        "                    if \"cheese\" in low_raw: req.update({\"soy\", \"cheese\"})\n",
        "                    if \"cream\"  in low_raw: req.update({\"soy\", \"cream\"})\n",
        "                    continue\n",
        "\n",
        "                # skip bare milk token\n",
        "                if c == \"milk\":\n",
        "                    dropped.add(raw.strip())\n",
        "                    continue\n",
        "\n",
        "                # --- drop all non-veg tokens ---\n",
        "                if _near_nonveg(c) or any(p in low_raw for p in _NONVEG_PHRASES):\n",
        "                    dropped.add(raw.strip())\n",
        "                    continue\n",
        "\n",
        "            # default path\n",
        "            req.add(c)\n",
        "\n",
        "            # track exact protein requests\n",
        "            if c in PROTEIN_TOKENS:\n",
        "                requested_proteins.add(c)\n",
        "\n",
        "    return req, dropped, requested_proteins\n",
        "\n",
        "\n",
        "\n",
        "# ---- Images\n",
        "# ---------------------- Image retrieval (food-only safe) ----------------------\n",
        "PEXELS_KEY = _get_env_or_secret(\"PEXELS_API_KEY\")\n"
      ],
      "id": "yfiI6DGkz-X9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "block",
        "id": "Fogoiymbz-X9"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "@st.cache_data(show_spinner=False, ttl=3600)\n",
        "def _pexels_image(query: str, per_page: int = 18, page: int = 1) -> Optional[str]:\n",
        "    \"\"\"Try to fetch a plated/food dish from Pexels.\"\"\"\n",
        "    if not PEXELS_KEY:\n",
        "        return None\n",
        "    try:\n",
        "        r = requests.get(\n",
        "            \"https://api.pexels.com/v1/search\",\n",
        "            headers={\"Authorization\": PEXELS_KEY, \"User-Agent\": \"SRF/1.0\"},\n",
        "            params={\n",
        "                \"query\": query,\n",
        "                \"per_page\": per_page,\n",
        "                \"page\": page,\n",
        "                \"orientation\": \"landscape\",\n",
        "                \"size\": \"medium\",\n",
        "            },\n",
        "            timeout=10,\n",
        "        )\n",
        "        r.raise_for_status()\n",
        "        js = r.json() or {}\n",
        "        photos = js.get(\"photos\") or []\n",
        "        # Prefer items whose ALT clearly indicates cooked/plated food.\n",
        "        food_terms = {\n",
        "            \"plated\", \"plate\", \"dish\", \"meal\", \"kebab\", \"skewer\", \"grill\", \"bbq\",\n",
        "            \"tandoori\", \"curry\", \"pasta\", \"salad\", \"soup\", \"pilaf\", \"rice\",\n",
        "            \"noodles\", \"steak\", \"burger\", \"taco\", \"sushi\", \"biryani\", \"shawarma\"\n",
        "        }\n",
        "        for p in photos:\n",
        "            alt = (p.get(\"alt\") or \"\").lower()\n",
        "            if any(k in alt for k in food_terms):\n",
        "                src = (p.get(\"src\") or {})\n",
        "                return src.get(\"medium\") or src.get(\"large\") or src.get(\"original\")\n",
        "        # Fallback to the first result if nothing matched the strict filter.\n",
        "        if photos:\n",
        "            src = (photos[0].get(\"src\") or {})\n",
        "            return src.get(\"medium\") or src.get(\"large\") or src.get(\"original\")\n",
        "    except Exception:\n",
        "        return None\n",
        "    return None\n"
      ],
      "id": "Fogoiymbz-X9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "_valid_food_img",
        "id": "ybonSaPJz-X9"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def _valid_food_img(url: Optional[str]) -> bool:\n",
        "    \"\"\"Basic sanity checks; reject obvious non-food or malformed URLs.\"\"\"\n",
        "    if not url:\n",
        "        return False\n",
        "    u = url.lower()\n",
        "    reject = [\n",
        "        \"monster energy\", \"can of\", \"soda\", \"soft drink\", \"coffee cup\",\n",
        "        \"fruit\", \"berries\", \"banana\", \"orange\", \"apple\", \"juice\"\n",
        "    ]\n",
        "    return u.startswith((\"http://\", \"https://\")) and not any(b in u for b in reject)\n",
        "\n",
        "# Deterministic, image-only FOOD fallbacks (no people/streets/objects).\n",
        "FALLBACK_VEG_IMAGES = [\n",
        "    \"https://img.icons8.com/color/512/salad.png\",\n",
        "    \"https://img.icons8.com/color/512/vegetarian-food.png\",\n",
        "    \"https://img.icons8.com/color/512/greek-salad.png\",\n",
        "    \"https://img.icons8.com/color/512/vegan-food.png\",\n",
        "]\n",
        "FALLBACK_NONVEG_IMAGES = [\n",
        "    \"https://img.icons8.com/color/512/steak.png\",\n",
        "    \"https://img.icons8.com/color/512/bbq.png\",\n",
        "    \"https://img.icons8.com/color/512/chicken.png\",\n",
        "    \"https://img.icons8.com/color/512/fish-food.png\",\n",
        "]\n"
      ],
      "id": "ybonSaPJz-X9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "_fallback_food_image",
        "id": "PUHtEe0kz-X9"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def _fallback_food_image(vegetarian: bool, title: str, salt: str, seen: set[str]) -> str:\n",
        "    \"\"\"Guaranteed safe food icon; deterministic w.r.t. (title, salt).\"\"\"\n",
        "    pool = FALLBACK_VEG_IMAGES if vegetarian else FALLBACK_NONVEG_IMAGES\n",
        "    h = int(hashlib.sha1((title + \"|\" + salt).encode(\"utf-8\")).hexdigest(), 16)\n",
        "    idx = h % len(pool)\n",
        "    # Avoid duplicates inside a single search session.\n",
        "    for j in range(len(pool)):\n",
        "        url = pool[(idx + j) % len(pool)]\n",
        "        if url not in seen:\n",
        "            seen.add(url)\n",
        "            return url\n",
        "    return pool[idx]\n"
      ],
      "id": "PUHtEe0kz-X9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "_resolve_image",
        "id": "xavaG8SDz-X9"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def _resolve_image(img: Optional[str], vegetarian: bool, title: str, salt: str, seen: set[str]) -> str:\n",
        "    \"\"\"\n",
        "    Rule:\n",
        "      1) If the recipe already has a valid food image and it's not reused -> keep it.\n",
        "      2) Else query Pexels with salted pagination for diversity.\n",
        "      3) Else use a guaranteed-safe food fallback (no loremflickr).\n",
        "    \"\"\"\n",
        "    # 1) Provided image\n",
        "    if img and _valid_food_img(img) and img not in seen:\n",
        "        seen.add(img)\n",
        "        return img\n",
        "\n",
        "    # 2) Pexels query (salt controls page selection -> fresh images each search)\n",
        "    q = (title or \"recipe\").lower()\n",
        "    if any(k in q for k in [\"bbq\", \"barbecue\", \"grill\", \"grilled\", \"kebab\", \"kabob\", \"skewer\", \"tandoori\"]):\n",
        "        q += \" plated grill kebab barbecue\"\n",
        "    else:\n",
        "        q += \" plated main course curry pasta salad soup pilaf\"\n",
        "        if vegetarian:\n",
        "            q += \" vegetarian\"\n",
        "    page = 1 + (int(hashlib.sha1((q + \"|\" + salt).encode(\"utf-8\")).hexdigest(), 16) % 3)\n",
        "    px = _pexels_image(q, per_page=18, page=page)\n",
        "    if px and px not in seen and _valid_food_img(px):\n",
        "        seen.add(px)\n",
        "        return px\n",
        "\n",
        "    # 3) Guaranteed-safe fallback (icons8 food set)\n",
        "    return _fallback_food_image(vegetarian, title or q, salt, seen)\n",
        "\n",
        "\n",
        "# ---------------------- Step generator (distinct per card) -------------\n"
      ],
      "id": "xavaG8SDz-X9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "distinct_steps_from_ingredients",
        "id": "bAkvucx1z-X9"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def distinct_steps_from_ingredients(title: str,\n",
        "                                    ings: list[str],\n",
        "                                    style: str,\n",
        "                                    seed: int,\n",
        "                                    required_tokens: Optional[set[str]]=None) -> list[str]:\n",
        "    rng = random.Random(seed)\n",
        "    low_join = \" \".join(_norm(x) for x in ings)\n",
        "    has_tomato  = any(k in low_join for k in [\"tomato\",\"passata\"])\n",
        "    has_dairy   = any(k in low_join for k in [\"cream\",\"yogurt\",\"cheese\",\"parmesan\",\"paneer\",\"feta\",\"milk\"])\n",
        "    has_meat    = any(_near_nonveg(t) for t in _tokset(ings))\n",
        "    arom        = [w for w in ings if any(x in _norm(w) for x in [\"garlic\",\"onion\",\"ginger\",\"shallot\",\"leek\"])]\n",
        "    fat         = [w for w in ings if any(x in _norm(w) for x in [\"olive oil\",\"oil\",\"butter\",\"ghee\",\"sesame oil\"])]\n",
        "\n",
        "    pan = rng.choice([\"skillet\",\"Dutch oven\",\"saucepan\",\"braiser\"])\n",
        "    steps: list[str] = []\n",
        "    steps.append(\"Prep produce and seasoning.\")\n",
        "    if required_tokens:\n",
        "        req_line = \", \".join(sorted(required_tokens))\n",
        "        steps.append(f\"Keep required items handy: {req_line}.\")\n",
        "\n",
        "    if style in {\"skillet\",\"one-pot pasta\",\"pilaf\",\"curry\"}:\n",
        "        steps.append(f\"Preheat {pan} on medium; add {rng.choice(fat) if fat else 'oil'}.\")\n",
        "        if arom:\n",
        "            steps.append(f\"Sweat {', '.join(arom[:2])} with a pinch of salt until fragrant.\")\n",
        "\n",
        "    if style == \"one-pot pasta\":\n",
        "        steps += [\n",
        "            \"Add dry pasta; stir to coat.\",\n",
        "            f\"Pour in { 'tomato passata' if has_tomato else 'stock/water' } to cover; simmer, stirring.\",\n",
        "            \"Finish glossy with starchy liquid; fold through herbs/cheese.\"\n",
        "        ]\n",
        "    elif style == \"pilaf\":\n",
        "        steps += [\n",
        "            \"Rinse rice until clear; toast in fat 1‚Äì2 min.\",\n",
        "            \"Add 1.8√ó hot stock; cover and simmer gently 12‚Äì15 min.\",\n",
        "            \"Steam off heat 5 min; fluff.\"\n",
        "        ]\n",
        "    elif style == \"curry\":\n",
        "        steps += [\n",
        "            \"Bloom ground spices 30‚Äì60 s.\",\n",
        "            f\"Add tomatoes and { 'yogurt/cream' if has_dairy else 'water' }; simmer to napp√©.\",\n",
        "            \"Balance with citrus; finish with herbs.\"\n",
        "        ]\n",
        "    elif style == \"tray bake\":\n",
        "        steps += [\n",
        "            \"Preheat oven to 210 ¬∞C (410 ¬∞F).\",\n",
        "            \"Toss components with oil, salt, pepper; spread on tray.\",\n",
        "            \"Roast to caramelization, tossing once.\"\n",
        "        ]\n",
        "    elif style == \"grill\":\n",
        "        steps += [\n",
        "            \"Preheat grill/pan to high; oil grates.\",\n",
        "            \"Thread or arrange components; pat dry and season.\",\n",
        "            \"Grill to char marks, basting as needed; finish to doneness.\"\n",
        "        ]\n",
        "    elif style == \"stir fry\":\n",
        "        steps += [\n",
        "            \"Heat wok to smoking; add oil.\",\n",
        "            \"Stir-fry aromatics; add items in batches for sear.\",\n",
        "            \"Deglaze (soy/citrus); thicken lightly if needed.\"\n",
        "        ]\n",
        "    elif style == \"soup\":\n",
        "        steps += [\n",
        "            \"Sweat base vegetables; cover with liquid.\",\n",
        "            \"Simmer until flavors meld; season.\",\n",
        "            \"Finish with fresh herbs.\"\n",
        "        ]\n",
        "    elif style == \"salad\":\n",
        "        steps += [\n",
        "            \"Whisk dressing.\",\n",
        "            \"Toss chopped components just before serving.\",\n",
        "            \"Top with herbs/cheese/seeds.\"\n",
        "        ]\n",
        "    else:  # skillet default\n",
        "        steps += [\n",
        "            f\"Sear {'protein' if has_meat else 'vegetables'}; deglaze with { 'tomato' if has_tomato else 'stock' }.\",\n",
        "            \"Simmer to desired thickness.\"\n",
        "        ]\n",
        "\n",
        "    finishers = [\"adjust salt and acidity\"]\n",
        "    if has_dairy:  finishers.append(\"fold dairy off heat\")\n",
        "    if has_tomato: finishers.append(\"balance with a pinch of sugar or vinegar\")\n",
        "    steps.append(\"Finally \" + \"; \".join(finishers) + \".\")\n",
        "    steps.append(\"Rest briefly; garnish and serve.\")\n",
        "\n",
        "    # ensure distinct, trimmed, ‚â§10\n",
        "    seen, clean = set(), []\n",
        "    for s in steps:\n",
        "        s2 = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "        if s2 and s2 not in seen:\n",
        "            clean.append(s2); seen.add(s2)\n",
        "        if len(clean) == 10: break\n",
        "    return clean\n",
        "\n",
        "# --------------------------- Local Search Engine -----------------------\n"
      ],
      "id": "bAkvucx1z-X9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "LocalRecipeIndex",
        "id": "Vn4gXOp_z-X9"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "class LocalRecipeIndex:\n",
        "    def __init__(self, df: Optional[pd.DataFrame]):\n",
        "        self.ok=False; self.df=pd.DataFrame()\n",
        "        if df is None or df.empty: return\n",
        "        use=df.copy()\n",
        "        for col in [\"title\",\"ingredients\",\"steps\",\"image\",\"diet\"]:\n",
        "            use[col]=use.get(col,pd.Series(dtype=str)).fillna(\"\")\n",
        "        use[\"blob\"]=(use[\"title\"].astype(str)+\" \"+\n",
        "                     use[\"ingredients\"].astype(str)+\" \"+\n",
        "                     use[\"steps\"].astype(str)).str.lower()\n",
        "        try:\n",
        "            from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "            self.vectorizer=TfidfVectorizer(min_df=1,max_df=0.9,ngram_range=(1,2))\n",
        "            self.feats=self.vectorizer.fit_transform(use[\"blob\"].tolist())\n",
        "            self.df=use.reset_index(drop=True); self.ok=True\n",
        "        except Exception: self.ok=False\n",
        "\n",
        "    @staticmethod\n",
        "    def _ings_query(ingredients: list[str]) -> str:\n",
        "        toks=[]\n",
        "        for x in ingredients: toks+=re.sub(r\"[^a-z0-9\\s]\",\" \",x.lower()).split()\n",
        "        return \" \".join(toks)\n",
        "\n",
        "    def search(self, ingredients: list[str], k: int = 24) -> list[dict]:\n",
        "        if not self.ok or not ingredients: return []\n",
        "        qv=self.vectorizer.transform([self._ings_query(ingredients)])\n",
        "        sims=(self.feats @ qv.T).toarray().ravel()\n",
        "        order=np.argsort(-sims); out=[]; seen_title=set()\n",
        "        for idx in order[:max(160,k)]:\n",
        "            row=self.df.iloc[idx]\n",
        "            title=str(row[\"title\"]).strip()\n",
        "            if title.lower() in seen_title: continue\n",
        "            steps=[s.strip() for s in re.split(r\"\\r?\\n|\\|\\|?|\\.\\s+(?=[A-Z])\",str(row[\"steps\"])) if s.strip()]\n",
        "            ings=[s.strip() for s in re.split(r\",|\\|\",str(row[\"ingredients\"])) if s.strip()]\n",
        "            img=str(row.get(\"image\",\"\")).strip()\n",
        "            out.append({\"title\":title,\"image\":img,\n",
        "                        \"ingredients\":ings,\"steps\":steps,\"source\":\"local\",\"score\":float(sims[idx])})\n",
        "            seen_title.add(title.lower())\n",
        "            if len(out)==k: break\n",
        "        return out\n"
      ],
      "id": "Vn4gXOp_z-X9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "block",
        "id": "UgDuZ44Tz-X-"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "@st.cache_resource(show_spinner=False)\n",
        "def _load_local_corpus()->LocalRecipeIndex:\n",
        "    df=None; csvp=ASSETS_DIR/\"recipes.csv\"; parp=ASSETS_DIR/\"recipes.parquet\"\n",
        "    try:\n",
        "        if parp.exists(): df=pd.read_parquet(parp)\n",
        "        elif csvp.exists(): df=pd.read_csv(csvp)\n",
        "    except Exception: df=None\n",
        "    return LocalRecipeIndex(df)\n",
        "LOCAL_INDEX=_load_local_corpus()\n",
        "\n",
        "# ---------------------- External APIs (optional) -----------------------\n",
        "SPOON_KEY  = _get_env_or_secret(\"SPOONACULAR_KEY\")\n"
      ],
      "id": "UgDuZ44Tz-X-"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "_spoon_get",
        "id": "50NCczP6z-X-"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def _spoon_get(url: str, params: dict) -> dict | None:\n",
        "    if not SPOON_KEY: return None\n",
        "    try:\n",
        "        p={\"apiKey\":SPOON_KEY}; p.update(params or {})\n",
        "        r=requests.get(url, params=p, timeout=12, headers={\"User-Agent\":\"SRF/1.0\"})\n",
        "        if r.status_code in (401,402,403): return None\n",
        "        r.raise_for_status(); return r.json()\n",
        "    except Exception: return None\n"
      ],
      "id": "50NCczP6z-X-"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "block",
        "id": "LjAHpRt8z-X-"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "@st.cache_data(show_spinner=False, ttl=900)\n",
        "def fetch_spoonacular(ingredients: list[str], n: int, vegetarian: bool) -> list[dict]:\n",
        "    if not ingredients or not SPOON_KEY: return []\n",
        "    q=\",\".join([i.strip() for i in ingredients if i.strip()])\n",
        "    url=\"https://api.spoonacular.com/recipes/complexSearch\"\n",
        "    params={\"includeIngredients\":q,\"fillIngredients\":True,\"addRecipeInformation\":True,\n",
        "            \"instructionsRequired\":True,\"number\":max(18,n),\"sort\":\"max-used-ingredients\",\"ranking\":2}\n",
        "    if vegetarian: params[\"diet\"]=\"vegetarian\"\n",
        "    js=_spoon_get(url, params)\n",
        "    if not js or \"results\" not in js: return []\n",
        "    out=[]\n",
        "    for rec in js[\"results\"]:\n",
        "        title=(rec.get(\"title\") or \"\").strip()\n",
        "        image=(rec.get(\"image\") or \"\").strip()\n",
        "        ingr=[(it.get(\"original\") or it.get(\"name\",\"\")).strip()\n",
        "              for it in (rec.get(\"extendedIngredients\") or []) if (it.get(\"original\") or it.get(\"name\",\"\"))]\n",
        "        steps=[]\n",
        "        for block in (rec.get(\"analyzedInstructions\") or []):\n",
        "            for stp in (block.get(\"steps\") or []):\n",
        "                txt=(stp.get(\"step\") or \"\").strip()\n",
        "                if txt: steps.append(txt)\n",
        "        if vegetarian and not _is_vegetarian(ingr):  # hard guard\n",
        "            continue\n",
        "        if title and ingr:\n",
        "            out.append({\"title\":title,\"image\":image,\"ingredients\":ingr,\"steps\":steps,\"source\":\"spoon\",\"score\":0.7})\n",
        "        if len(out)==n: break\n",
        "    return out\n"
      ],
      "id": "LjAHpRt8z-X-"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "block",
        "id": "Lyl43KNsz-X-"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "@st.cache_data(show_spinner=False, ttl=900)\n",
        "def fetch_mealdb(ingredients: list[str], n: int, vegetarian: bool) -> list[dict]:\n",
        "    try:\n",
        "        seeds=[i for i in (ingredients[:3] or [\"tomato\"])]\n",
        "        pool=[]\n",
        "        for seed in seeds:\n",
        "            js=requests.get(\"https://www.themealdb.com/api/json/v1/1/filter.php\",\n",
        "                            params={\"i\":seed},timeout=8, headers={\"User-Agent\":\"SRF/1.0\"}).json()\n",
        "            for m in (js.get(\"meals\") or [])[:10]:\n",
        "                pool.append((m[\"idMeal\"], m.get(\"strMeal\",\"\").strip(), (m.get(\"strMealThumb\",\"\") or \"\").strip()))\n",
        "        out=[]\n",
        "        for mid, title, img in pool[:24]:\n",
        "            det=requests.get(\"https://www.themealdb.com/api/json/v1/1/lookup.php\",\n",
        "                             params={\"i\":mid},timeout=8, headers={\"User-Agent\":\"SRF/1.0\"}).json()\n",
        "            meal=(det.get(\"meals\") or [None])[0]\n",
        "            if not meal: continue\n",
        "            ings=[]\n",
        "            for k in range(1,21):\n",
        "                nm=(meal.get(f\"strIngredient{k}\") or \"\").strip()\n",
        "                ms=(meal.get(f\"strMeasure{k}\") or \"\").strip()\n",
        "                if nm: ings.append(f\"{ms} {nm}\".strip())\n",
        "            ins=(meal.get(\"strInstructions\") or \"\").strip()\n",
        "            steps=[s.strip() for s in re.split(r\"\\r?\\n|\\.\\s+(?=[A-Z])\",ins) if s.strip()] if ins else []\n",
        "            if vegetarian and not _is_vegetarian(ings):  # guard\n",
        "                continue\n",
        "            cand={\"title\":title,\"image\":img,\"ingredients\":ings,\"steps\":steps,\"source\":\"mealdb\",\"score\":0.5}\n",
        "            out.append(cand)\n",
        "        return out[:n]\n",
        "    except Exception: return []\n"
      ],
      "id": "Lyl43KNsz-X-"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "fetch_mealdb_seafood",
        "id": "rphTz4s7z-X-"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def fetch_mealdb_seafood(n=25):\n",
        "    out = []\n",
        "    try:\n",
        "        url = \"https://www.themealdb.com/api/json/v1/1/filter.php?c=Seafood\"\n",
        "        r = requests.get(url, timeout=8)\n",
        "        data = r.json().get(\"meals\") or []\n",
        "        for m in data[:n]:\n",
        "            out.append({\n",
        "                \"title\": m.get(\"strMeal\",\"\"),\n",
        "                \"image\": m.get(\"strMealThumb\",\"\"),\n",
        "                \"ingredients\": [\"seafood\",\"fish\"],  # placeholder\n",
        "                \"steps\": [],\n",
        "                \"source\": \"mealdb_seafood\",\n",
        "                \"score\": 0.55\n",
        "            })\n",
        "    except Exception:\n",
        "        pass\n",
        "    return out\n",
        "\n",
        "\n",
        "# ------------------------- Plot helpers (Plotly) -----------------------\n"
      ],
      "id": "rphTz4s7z-X-"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "bar_colored",
        "id": "FyShq1Ixz-X-"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def bar_colored(x_labels, y_vals, title_y=\"\", height=300):\n",
        "    bars=[go.Bar(name=str(x), x=[x], y=[y]) for x,y in zip(x_labels,y_vals)]\n",
        "    fig=go.Figure(data=bars)\n",
        "    fig.update_layout(barmode=\"group\", margin=dict(l=0,r=0,t=10,b=0),\n",
        "                      yaxis=dict(title=title_y, rangemode=\"tozero\"),\n",
        "                      xaxis=dict(title=\"\"), height=height, template=\"simple_white\", showlegend=False)\n",
        "    return fig\n"
      ],
      "id": "FyShq1Ixz-X-"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "kcal_line",
        "id": "9djf9SDDz-X-"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def kcal_line(df_days, df_kcal):\n",
        "    fig=go.Figure(); fig.add_trace(go.Scatter(x=df_days,y=df_kcal,mode=\"lines+markers\",name=\"kcal\"))\n",
        "    fig.update_layout(height=320, template=\"simple_white\", margin=dict(l=0,r=0,t=10,b=0), yaxis=dict(title=\"kcal\"))\n",
        "    return fig\n"
      ],
      "id": "9djf9SDDz-X-"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "macros_stacked",
        "id": "3vbo8xE8z-X-"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def macros_stacked(df_days, df_prot, df_fat, df_carb):\n",
        "    fig=go.Figure()\n",
        "    fig.add_trace(go.Bar(x=df_days,y=df_prot,name=\"Protein\"))\n",
        "    fig.add_trace(go.Bar(x=df_days,y=df_fat, name=\"Fat\"))\n",
        "    fig.add_trace(go.Bar(x=df_days,y=df_carb,name=\"Carbs\"))\n",
        "    fig.update_layout(barmode=\"stack\",height=320,template=\"simple_white\",\n",
        "                      margin=dict(l=0,r=0,t=10,b=0),yaxis=dict(title=\"grams\"))\n",
        "    return fig\n",
        "\n",
        "# ----------------------------- PDF utils -------------------------------\n"
      ],
      "id": "3vbo8xE8z-X-"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "recipe_pdf",
        "id": "Ccnb6D2rz-X_"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def recipe_pdf(\n",
        "    title: str,\n",
        "    ingredients: List[str],\n",
        "    recipe_text: str,\n",
        "    nutrition: Dict[str, float],\n",
        "    image_url: str\n",
        ") -> Optional[bytes]:\n",
        "    \"\"\"Build a well-formatted, single-file PDF for a recipe.\n",
        "\n",
        "    - Graceful image handling (aspect-preserving, network-safe).\n",
        "    - Bulleted ingredients; numbered instructions.\n",
        "    - Compact, readable styles and a clean nutrition table.\n",
        "    - Page numbers in the footer.\n",
        "    \"\"\"\n",
        "    if not PDF_OK:\n",
        "        return None\n",
        "    try:\n",
        "        import io\n",
        "        import requests\n",
        "        from reportlab.lib.pagesizes import letter\n",
        "        from reportlab.lib.units import inch\n",
        "        from reportlab.lib import colors\n",
        "        from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
        "        from reportlab.platypus import (\n",
        "            SimpleDocTemplate, Paragraph, Spacer, Image, Table, TableStyle,\n",
        "            ListFlowable, ListItem, KeepTogether\n",
        "        )\n",
        "\n",
        "        # --------------------- helpers ---------------------\n",
        "        def _safe_text_lines(txt: str) -> list[str]:\n",
        "            return [ln.strip() for ln in (txt or \"\").split(\"\\n\") if ln.strip()]\n",
        "\n",
        "        def _fetch_image_bytes(url: str, timeout: float = 10.0) -> Optional[bytes]:\n",
        "            if not url or not url.startswith((\"http://\", \"https://\")):\n",
        "                return None\n",
        "            try:\n",
        "                r = requests.get(url, timeout=timeout, headers={\"User-Agent\": \"SRF/1.0\"})\n",
        "                r.raise_for_status()\n",
        "                return r.content\n",
        "            except Exception:\n",
        "                return None\n",
        "\n",
        "        def _aspect_image(img_bytes: bytes, max_w: float, max_h: float) -> Optional[Image]:\n",
        "            try:\n",
        "                bio = io.BytesIO(img_bytes)\n",
        "                im = Image(bio)\n",
        "                iw, ih = im.wrap(0, 0)\n",
        "                if iw <= 0 or ih <= 0:\n",
        "                    return None\n",
        "                scale = min(max_w / iw, max_h / ih, 1.0)\n",
        "                im._restrictSize(iw * scale, ih * scale)\n",
        "                return im\n",
        "            except Exception:\n",
        "                return None\n",
        "\n",
        "        # --------------------- document ---------------------\n",
        "        buf = io.BytesIO()\n",
        "        doc = SimpleDocTemplate(\n",
        "            buf,\n",
        "            pagesize=letter,\n",
        "            leftMargin=0.75 * inch,\n",
        "            rightMargin=0.75 * inch,\n",
        "            topMargin=0.65 * inch,\n",
        "            bottomMargin=0.65 * inch,\n",
        "            title=title,\n",
        "            author=\"Smart Recipe Finder (PRO)\",\n",
        "        )\n",
        "\n",
        "        styles = getSampleStyleSheet()\n",
        "        # Tweak defaults for a cleaner look\n",
        "        styles[\"Title\"].fontSize = 20\n",
        "        styles[\"Title\"].leading = 24\n",
        "        styles[\"Heading2\"].spaceBefore = 10\n",
        "        styles[\"Heading2\"].spaceAfter = 6\n",
        "\n",
        "        body = ParagraphStyle(\n",
        "            \"Body\",\n",
        "            parent=styles[\"Normal\"],\n",
        "            fontSize=10.8,\n",
        "            leading=14.2,\n",
        "            spaceAfter=3,\n",
        "        )\n",
        "        bullet_style = ParagraphStyle(\n",
        "            \"Bullet\",\n",
        "            parent=body,\n",
        "            leftIndent=14,\n",
        "            bulletIndent=6,\n",
        "        )\n",
        "\n",
        "        # Footer with page numbers\n",
        "        def _footer(canvas, doc_):\n",
        "            canvas.saveState()\n",
        "            footer_txt = f\"{eng_escape(title)} ‚Äî page {doc_.page}\"\n",
        "            canvas.setFont(\"Helvetica\", 9)\n",
        "            canvas.setFillGray(0.4)\n",
        "            canvas.drawRightString(\n",
        "                doc_.pagesize[0] - doc_.rightMargin,\n",
        "                0.45 * inch,\n",
        "                footer_txt\n",
        "            )\n",
        "            canvas.restoreState()\n",
        "\n",
        "        story: list = []\n",
        "\n",
        "        # Title\n",
        "        story.append(Paragraph(f\"<b>{eng_escape(title)}</b>\", styles[\"Title\"]))\n",
        "        story.append(Spacer(1, 8))\n",
        "\n",
        "        # Optional hero image (scaled to fit)\n",
        "        img_bytes = _fetch_image_bytes(image_url)\n",
        "        if img_bytes:\n",
        "            im = _aspect_image(img_bytes, max_w=6.2 * inch, max_h=3.5 * inch)\n",
        "            if im:\n",
        "                story.append(im)\n",
        "                story.append(Spacer(1, 10))\n",
        "\n",
        "        # Ingredients (bulleted)\n",
        "        story.append(Paragraph(\"<b>Ingredients</b>\", styles[\"Heading2\"]))\n",
        "        if ingredients:\n",
        "            bullets = [\n",
        "                ListItem(Paragraph(eng_escape(it), bullet_style), bulletText=\"‚Ä¢\")\n",
        "                for it in ingredients\n",
        "            ]\n",
        "            story.append(ListFlowable(bullets, bulletType=\"bullet\", start=\"‚Ä¢\", leftIndent=6))\n",
        "        else:\n",
        "            story.append(Paragraph(\"‚Äî\", body))\n",
        "        story.append(Spacer(1, 6))\n",
        "\n",
        "        # Instructions (numbered)\n",
        "        story.append(Paragraph(\"<b>Instructions</b>\", styles[\"Heading2\"]))\n",
        "        steps = _safe_text_lines(recipe_text)\n",
        "        if steps:\n",
        "            numbered = [\n",
        "                ListItem(Paragraph(eng_escape(s), body), value=i + 1)\n",
        "                for i, s in enumerate(steps)\n",
        "            ]\n",
        "            story.append(ListFlowable(numbered, bulletType=\"1\", start=\"1\", leftIndent=6))\n",
        "        else:\n",
        "            story.append(Paragraph(\"‚Äî\", body))\n",
        "        story.append(Spacer(1, 10))\n",
        "\n",
        "        # Nutrition table\n",
        "        k = float(nutrition.get(\"kcal\", 0.0) or 0.0)\n",
        "        p = float(nutrition.get(\"protein\", 0.0) or 0.0)\n",
        "        f = float(nutrition.get(\"fat\", 0.0) or 0.0)\n",
        "        c = float(nutrition.get(\"carbs\", 0.0) or 0.0)\n",
        "\n",
        "        story.append(Paragraph(\"<b>Nutrition (approx.)</b>\", styles[\"Heading2\"]))\n",
        "        data = [\n",
        "            [\"Calories (kcal)\", f\"{k:.1f}\"],\n",
        "            [\"Protein (g)\",     f\"{p:.1f}\"],\n",
        "            [\"Fat (g)\",         f\"{f:.1f}\"],\n",
        "            [\"Carbs (g)\",       f\"{c:.1f}\"],\n",
        "        ]\n",
        "        tbl = Table(data, colWidths=[2.2 * inch, 1.2 * inch])\n",
        "        tbl.setStyle(TableStyle([\n",
        "            (\"GRID\",        (0, 0), (-1, -1), 0.4, colors.black),\n",
        "            (\"BACKGROUND\",  (0, 0), (-1, 0), colors.whitesmoke),\n",
        "            (\"TEXTCOLOR\",   (0, 0), (0, -1), colors.HexColor(\"#333333\")),\n",
        "            (\"ALIGN\",       (0, 0), (-1, -1), \"LEFT\"),\n",
        "            (\"VALIGN\",      (0, 0), (-1, -1), \"MIDDLE\"),\n",
        "            (\"ROWBACKGROUNDS\", (0, 1), (-1, -1), [colors.Color(1,1,1), colors.Color(0.98,0.98,0.98)]),\n",
        "            (\"LEFTPADDING\", (0, 0), (-1, -1), 6),\n",
        "            (\"RIGHTPADDING\",(0, 0), (-1, -1), 6),\n",
        "            (\"TOPPADDING\",  (0, 0), (-1, -1), 4),\n",
        "            (\"BOTTOMPADDING\",(0, 0), (-1, -1), 4),\n",
        "        ]))\n",
        "        story.append(KeepTogether(tbl))\n",
        "\n",
        "        # Build with footers\n",
        "        doc.build(story, onFirstPage=_footer, onLaterPages=_footer)\n",
        "        return buf.getvalue()\n",
        "\n",
        "    except Exception:\n",
        "        return None\n"
      ],
      "id": "Ccnb6D2rz-X_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "eng_escape",
        "id": "KUlAgWmlz-X_"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def eng_escape(s: str) -> str:\n",
        "    return s.replace(\"&\",\"&amp;\").replace(\"<\",\"&lt;\").replace(\">\",\"&gt;\")\n",
        "\n",
        "# ----------------------------- Translation & TTS -----------------------\n"
      ],
      "id": "KUlAgWmlz-X_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "translate_if",
        "id": "GIo1qwUSz-X_"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def translate_if(lines: list[str], lang_code: str) -> list[str]:\n",
        "    if lang_code == \"en\" or not TRANS_OK: return lines\n",
        "    try:\n",
        "        from deep_translator import GoogleTranslator\n",
        "        tr = GoogleTranslator(source=\"auto\", target=lang_code)\n",
        "        return [tr.translate(t) for t in lines]\n",
        "    except Exception:\n",
        "        return lines\n"
      ],
      "id": "GIo1qwUSz-X_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "_change_speed",
        "id": "4ujwc7Lxz-X_"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def _change_speed(seg, factor: float):\n",
        "    new_rate = int(seg.frame_rate * factor)\n",
        "    return seg._spawn(seg.raw_data, overrides={\"frame_rate\": new_rate}).set_frame_rate(seg.frame_rate)\n"
      ],
      "id": "4ujwc7Lxz-X_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "_shift_pitch",
        "id": "WtB_UUKRz-X_"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def _shift_pitch(seg, semitones: float):\n",
        "    factor = 2.0 ** (semitones / 12.0)\n",
        "    return _change_speed(seg, factor)\n",
        "\n",
        "VOICE = {\n",
        "    \"Neutral\": {\"speed\": 1.00, \"pitch\": 0.0},\n",
        "    \"Female-warm\": {\"speed\": 0.98, \"pitch\": +1.0},\n",
        "    \"Female-light\": {\"speed\": 1.03, \"pitch\": +2.0},\n",
        "    \"Male-soft\": {\"speed\": 0.99, \"pitch\": -1.0},\n",
        "    \"Male-deep\": {\"speed\": 0.96, \"pitch\": -6.0},   # deeper & slower\n",
        "    \"Fast\": {\"speed\": 1.08, \"pitch\": 0.0},\n",
        "    \"Calm\": {\"speed\": 0.95, \"pitch\": 0.0},\n",
        "}\n"
      ],
      "id": "WtB_UUKRz-X_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "tts_instructions",
        "id": "nl_SUiQcz-X_"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def tts_instructions(lines: List[str], lang_code: str, voice_preset: Dict[str, float], speed_factor: float) -> Optional[bytes]:\n",
        "    if not TTS_OK: return None\n",
        "    from gtts import gTTS\n",
        "    from pydub import AudioSegment\n",
        "    vp = dict(voice_preset or VOICE[\"Neutral\"]); vp[\"speed\"] = float(speed_factor)\n",
        "    full = AudioSegment.silent(duration=250)\n",
        "    for text in lines:\n",
        "        bio = io.BytesIO(); gTTS(text=text, lang=lang_code).write_to_fp(bio); bio.seek(0)\n",
        "        seg = AudioSegment.from_file(bio, format=\"mp3\")\n",
        "        seg = _shift_pitch(seg, vp.get(\"pitch\", 0.0)); seg = _change_speed(seg, vp.get(\"speed\", 1.0))\n",
        "        full += seg + AudioSegment.silent(duration=140)\n",
        "    out = io.BytesIO(); full.export(out, format=\"mp3\"); return out.getvalue()\n"
      ],
      "id": "nl_SUiQcz-X_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "podcast_script",
        "id": "iz7f7Vylz-X_"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def podcast_script(title: str,\n",
        "                   ingredients: list[str],\n",
        "                   steps: list[str],\n",
        "                   host_name: str,\n",
        "                   chef_name: str) -> list[str]:\n",
        "    \"\"\"\n",
        "    Host‚ÜîChef podcast script with discourse connectors instead of numeric steps.\n",
        "    - Uses all steps.\n",
        "    - If the recipe supplies a single long paragraph, split it to pseudo-steps.\n",
        "    - Keeps early Host prompts concise; Chef narrates instructions.\n",
        "    \"\"\"\n",
        "    def _clean(s: str) -> str:\n",
        "        s = \" \".join((s or \"\").strip().split())\n",
        "        while \"..\" in s:\n",
        "            s = s.replace(\"..\", \".\")\n",
        "        return s\n",
        "\n",
        "    title = _clean(title)\n",
        "    ingredients = [_clean(x) for x in (ingredients or []) if _clean(x)]\n",
        "    raw_steps = [ _clean(x) for x in (steps or []) if _clean(x) ]\n",
        "\n",
        "    # If the recipe provided only one blob, try to split into sentences/clauses.\n",
        "    if len(raw_steps) <= 1:\n",
        "        blob = raw_steps[0] if raw_steps else \"\"\n",
        "        # split on sentence boundaries or semicolons/bullets\n",
        "        chunks = []\n",
        "        for piece in re.split(r\"(?:\\.\\s+|\\n+|;|\\u2022|\\u25CF)\", blob):\n",
        "            p = _clean(piece)\n",
        "            if len(p) >= 4:\n",
        "                chunks.append(p)\n",
        "        if chunks:\n",
        "            raw_steps = chunks\n",
        "\n",
        "    # Connector sequence (last one is reserved for the final step)\n",
        "    connectors = [\"First,\", \"Then,\", \"Next,\", \"After that,\", \"Now,\", \"Meanwhile,\", \"Afterwards,\"]\n",
        "    final_connector = \"Finally,\"\n",
        "\n",
        "    lead = [\n",
        "        f\"{host_name}: Welcome to Calm Kitchen. Today we're cooking {title}.\",\n",
        "        f\"{host_name}: I'm joined by our chef, {chef_name}. Tell us about this dish.\",\n",
        "        f\"{chef_name}: Thanks. This recipe highlights {', '.join(ingredients[:3]) if ingredients else 'simple pantry staples'}.\",\n",
        "        f\"{host_name}: Great. Let's walk through the method.\"\n",
        "    ]\n",
        "\n",
        "    script = list(lead)\n",
        "\n",
        "    n = len(raw_steps)\n",
        "    for i, s in enumerate(raw_steps, start=1):\n",
        "        if i == n:\n",
        "            prefix = final_connector\n",
        "        else:\n",
        "            prefix = connectors[(i-1) % len(connectors)]\n",
        "        script.append(f\"{chef_name}: {prefix} {s}\")\n",
        "\n",
        "        # light pacing prompts early on only\n",
        "        if i == 1:\n",
        "            script.append(f\"{host_name}: Nice start. What comes next?\")\n",
        "        elif i == 2:\n",
        "            script.append(f\"{host_name}: Understood‚Äîkeep going.\")\n",
        "\n",
        "    script += [\n",
        "        f\"{host_name}: That wraps up {title}.\",\n",
        "        f\"{chef_name}: Adjust seasoning to taste and serve.\",\n",
        "        f\"{host_name}: Thanks for listening to Calm Kitchen.\"\n",
        "    ]\n",
        "    return script\n"
      ],
      "id": "iz7f7Vylz-X_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "tts_podcast",
        "id": "WUrgZqa2z-X_"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def tts_podcast(lines: list[str], lang_code: str,\n",
        "                host_voice: Dict[str, float], chef_voice: Dict[str, float],\n",
        "                host_speed: float, chef_speed: float) -> Optional[bytes]:\n",
        "    if not TTS_OK:\n",
        "        return None\n",
        "\n",
        "    from gtts import gTTS\n",
        "    from pydub import AudioSegment\n",
        "\n",
        "    # Voice profiles\n",
        "    host_v = dict(host_voice or VOICE.get(\"Neutral\", {}))\n",
        "    host_v[\"speed\"] = float(host_speed)\n",
        "\n",
        "    chef_v = dict(chef_voice or VOICE.get(\"Neutral\", {}))\n",
        "    chef_v[\"speed\"] = float(chef_speed)\n",
        "\n",
        "    final_audio = AudioSegment.silent(duration=250)\n",
        "\n",
        "    for ln in lines:\n",
        "        text = str(ln or \"\").strip()\n",
        "        if not text:\n",
        "            continue\n",
        "\n",
        "        # Safe dialog parsing: only split at the FIRST ‚Äú: ‚Äù\n",
        "        who, sep, say = text.partition(\": \")\n",
        "        if sep:\n",
        "            voice = chef_v if \"chef\" in who.lower() else host_v\n",
        "            utter = say\n",
        "        else:\n",
        "            voice = host_v\n",
        "            utter = text\n",
        "\n",
        "        if not utter:\n",
        "            continue\n",
        "\n",
        "        # TTS (with fallback if language fails)\n",
        "        bio = io.BytesIO()\n",
        "        try:\n",
        "            gTTS(text=utter, lang=lang_code).write_to_fp(bio)\n",
        "        except Exception:\n",
        "            bio = io.BytesIO()\n",
        "            gTTS(text=utter, lang=\"en\").write_to_fp(bio)  # fallback\n",
        "        bio.seek(0)\n",
        "\n",
        "        seg = AudioSegment.from_file(bio, format=\"mp3\")\n",
        "        seg = _shift_pitch(seg, float(voice.get(\"pitch\", 0.0)))\n",
        "        seg = _change_speed(seg, float(voice.get(\"speed\", 1.0)))\n",
        "\n",
        "        final_audio += seg + AudioSegment.silent(duration=140)\n",
        "\n",
        "    out = io.BytesIO()\n",
        "    final_audio.export(out, format=\"mp3\")\n",
        "    return out.getvalue()\n"
      ],
      "id": "WUrgZqa2z-X_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "podcast_pdf",
        "id": "v0TD9UPjz-YA"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def podcast_pdf(title: str, transcript_lines: list[str], lang_code: str = \"en\") -> Optional[bytes]:\n",
        "    if not PDF_OK:\n",
        "        return None\n",
        "    try:\n",
        "        from reportlab.lib.pagesizes import letter\n",
        "        from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
        "        from reportlab.lib.styles import getSampleStyleSheet\n",
        "\n",
        "        buf = io.BytesIO()\n",
        "        doc = SimpleDocTemplate(buf, pagesize=letter)\n",
        "        styles = getSampleStyleSheet()\n",
        "\n",
        "        # Localized PDF title\n",
        "        full_title = f\"{eng_escape(title)} {_lbl(lang_code, 'podcast_title_suffix')}\"\n",
        "\n",
        "        story = [\n",
        "            Paragraph(f\"<b>{full_title}</b>\", styles[\"Title\"]),\n",
        "            Spacer(1, 12),\n",
        "        ]\n",
        "\n",
        "        for ln in transcript_lines:\n",
        "            story.append(Paragraph(eng_escape(str(ln)), styles[\"Normal\"]))\n",
        "            story.append(Spacer(1, 4))\n",
        "\n",
        "        doc.build(story)\n",
        "        return buf.getvalue()\n",
        "\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "\n",
        "# --------------------- Coverage + distinct selection -------------------\n",
        "# ---- Protein/sweet heuristics for Non-veg filtering ----\n",
        "\n",
        "# ---- Protein vocab & helpers (drop-in replacement) --------------------\n",
        "PROTEIN_TOKENS = {\n",
        "    # Generic seafood\n",
        "    \"fish\",\"seafood\",\"fish fillet\",\"white fish\",\"saltfish\",\"smoked fish\",\n",
        "    \"fresh fish\",\"fried fish\",\"baked fish\",\"grilled fish\",\n",
        "\n",
        "    # Specific fishes\n",
        "    \"salmon\",\"salmon fillet\",\"tuna\",\"tuna steak\",\"cod\",\"cod fillet\",\n",
        "    \"haddock\",\"pollock\",\"tilapia\",\"catfish\",\"herring\",\"anchovy\",\"anchovies\",\n",
        "    \"sardine\",\"mackerel\",\"trout\",\"bass\",\"sea bass\",\"red snapper\",\"snapper\",\n",
        "    \"swordfish\",\"eel\",\n",
        "\n",
        "    # Molluscs\n",
        "    \"squid\",\"calamari\",\"octopus\",\"cuttlefish\",\n",
        "\n",
        "    # Shellfish\n",
        "    \"oyster\",\"oysters\",\"clam\",\"clams\",\"mussel\",\"mussels\",\"scallop\",\"scallops\",\n",
        "\n",
        "    # Crustaceans\n",
        "    \"shrimp\",\"shrimps\",\"prawn\",\"prawns\",\"king prawns\",\n",
        "    \"crab\",\"crab meat\",\"lobster\",\"lobster tail\",\"krill\",\n",
        "\n",
        "    # Land proteins\n",
        "    \"chicken\",\"chicken breast\",\"beef\",\"pork\",\"lamb\",\"turkey\",\"duck\",\"veal\",\"goat\",\n",
        "\n",
        "    # Eggs (special-cased elsewhere if needed)\n",
        "    \"egg\",\"eggs\",\n",
        "}\n",
        "\n",
        "# Canonical buckets used by the non-veg filter/boost\n",
        "SEAFOOD_SET = {\n",
        "    \"fish\",\"seafood\",\"fish fillet\",\"white fish\",\"saltfish\",\"smoked fish\",\n",
        "    \"fresh fish\",\"fried fish\",\"baked fish\",\"grilled fish\",\n",
        "    \"salmon\",\"salmon fillet\",\"tuna\",\"tuna steak\",\"cod\",\"cod fillet\",\n",
        "    \"haddock\",\"pollock\",\"tilapia\",\"catfish\",\"herring\",\"anchovy\",\"anchovies\",\n",
        "    \"sardine\",\"mackerel\",\"trout\",\"bass\",\"sea bass\",\"red snapper\",\"snapper\",\n",
        "    \"swordfish\",\"eel\",\"squid\",\"calamari\",\"octopus\",\"cuttlefish\",\"oyster\",\"oysters\",\n",
        "    \"clam\",\"clams\",\"mussel\",\"mussels\",\"scallop\",\"scallops\",\"shrimp\",\"shrimps\",\n",
        "    \"prawn\",\"prawns\",\"king prawns\",\"crab\",\"crab meat\",\"lobster\",\"lobster tail\",\"krill\",\n",
        "}\n",
        "LAND_SET = {\"chicken\",\"chicken breast\",\"beef\",\"pork\",\"lamb\",\"turkey\",\"duck\",\"veal\",\"goat\"}\n",
        "GENERIC_SEAFOOD = {\"fish\",\"seafood\",\"fish fillet\",\"white fish\",\"fresh fish\"}\n",
        "\n",
        "# Helpful aliases (normalize user intent to canon tokens)\n",
        "PROTEIN_ALIASES = {\n",
        "\n",
        "    # Beef\n",
        "    \"steak\": \"beef\",\n",
        "    \"ground beef\": \"beef\",\n",
        "    \"minced beef\": \"beef\",\n",
        "    \"beef mince\": \"beef\",\n",
        "    \"sirloin\": \"beef\",\n",
        "    \"tenderloin\": \"beef\",\n",
        "    \"ribeye\": \"beef\",\n",
        "    \"short rib\": \"beef\",\n",
        "    \"brisket\": \"beef\",\n",
        "    \"roast beef\": \"beef\",\n",
        "    \"mince\": \"beef\",     # heuristic\n",
        "\n",
        "    # Pork\n",
        "    \"ground pork\": \"pork\",\n",
        "    \"minced pork\": \"pork\",\n",
        "    \"pork chop\": \"pork\",\n",
        "    \"pork loin\": \"pork\",\n",
        "    \"pork belly\": \"pork\",\n",
        "    \"ham\": \"pork\",\n",
        "    \"bacon\": \"pork\",\n",
        "\n",
        "    # Chicken\n",
        "    \"drumstick\": \"chicken\",\n",
        "    \"thigh\": \"chicken\",\n",
        "    \"breast\": \"chicken\",\n",
        "    \"chicken breast\": \"chicken\",\n",
        "    \"chicken thigh\": \"chicken\",\n",
        "    \"chicken wing\": \"chicken\",\n",
        "    \"wing\": \"chicken\",\n",
        "    \"wings\": \"chicken\",\n",
        "    \"ground chicken\": \"chicken\",\n",
        "    \"minced chicken\": \"chicken\",\n",
        "\n",
        "    # Turkey\n",
        "    \"turkey breast\": \"turkey\",\n",
        "    \"ground turkey\": \"turkey\",\n",
        "    \"minced turkey\": \"turkey\",\n",
        "\n",
        "    # Lamb / Goat\n",
        "    \"lamb chop\": \"lamb\",\n",
        "    \"lamb shank\": \"lamb\",\n",
        "    \"ground lamb\": \"lamb\",\n",
        "    \"minced lamb\": \"lamb\",\n",
        "    \"mutton\": \"lamb\",\n",
        "    \"goat\": \"lamb\",\n",
        "\n",
        "    # Generic fillet/filet ‚Üí fish\n",
        "    \"fillet\": \"fish\",\n",
        "    \"filet\": \"fish\",\n",
        "    \"fish fillet\": \"fish\",\n",
        "    \"fish filet\": \"fish\",\n",
        "\n",
        "    # General seafood terms\n",
        "    \"seafood\": \"whitefish\",\n",
        "    \"fish\": \"fish\",\n",
        "    \"fishes\": \"fish\",\n",
        "    \"white fish\": \"whitefish\",\n",
        "    \"whitefish\": \"whitefish\",\n",
        "\n",
        "    # Common fish types\n",
        "    \"salmon fillet\": \"salmon\",\n",
        "    \"salmon steak\": \"salmon\",\n",
        "    \"cod fillet\": \"cod\",\n",
        "    \"haddock fillet\": \"haddock\",\n",
        "    \"trout fillet\": \"trout\",\n",
        "    \"tilapia fillet\": \"tilapia\",\n",
        "    \"bass\": \"whitefish\",\n",
        "    \"sea bass\": \"whitefish\",\n",
        "    \"snapper\": \"whitefish\",\n",
        "    \"red snapper\": \"whitefish\",\n",
        "\n",
        "    # Tuna variations\n",
        "    \"tuna steak\": \"tuna\",\n",
        "    \"tuna fillet\": \"tuna\",\n",
        "    \"canned tuna\": \"tuna\",\n",
        "    \"tuna in water\": \"tuna\",\n",
        "    \"tuna in oil\": \"tuna\",\n",
        "\n",
        "    # Oily fish\n",
        "    \"mackerel fillet\": \"mackerel\",\n",
        "    \"sardine\": \"sardines\",\n",
        "    \"sardines\": \"sardines\",\n",
        "    \"anchovy\": \"anchovy\",\n",
        "    \"anchovies\": \"anchovy\",\n",
        "\n",
        "    # Crustaceans\n",
        "    \"shrimp\": \"shrimp\",\n",
        "    \"shrimps\": \"shrimp\",\n",
        "    \"prawn\": \"shrimp\",\n",
        "    \"prawns\": \"shrimp\",\n",
        "    \"king prawn\": \"shrimp\",\n",
        "    \"crab meat\": \"crab\",\n",
        "    \"crab\": \"crab\",\n",
        "    \"lobster tail\": \"lobster\",\n",
        "    \"lobster\": \"lobster\",\n",
        "\n",
        "    # Molluscs\n",
        "    \"squid\": \"squid\",\n",
        "    \"calamari\": \"squid\",\n",
        "    \"octopus\": \"octopus\",\n",
        "    \"cuttlefish\": \"squid\",  # common grouping\n",
        "    \"scallop\": \"scallops\",\n",
        "    \"scallops\": \"scallops\",\n",
        "    \"clam\": \"clams\",\n",
        "    \"clams\": \"clams\",\n",
        "    \"mussel\": \"mussels\",\n",
        "    \"mussels\": \"mussels\",\n",
        "}\n",
        "\n",
        "SWEET_HINTS = {\n",
        "    \"dessert\",\"pudding\",\"cake\",\"brownie\",\"cookie\",\"ice cream\",\"whipped cream\",\n",
        "    \"custard\",\"sweet\",\"sugar\",\"syrup\",\"strawberry\",\"strawberries\",\"banana\",\"chocolate\",\n",
        "}\n"
      ],
      "id": "v0TD9UPjz-YA"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "_looks_sweet",
        "id": "TUZJqTfKz-YA"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def _looks_sweet(title: str, ings: list[str]) -> bool:\n",
        "    blob = (str(title) + \" \" + \" \".join(ings)).lower()\n",
        "    return any(k in blob for k in SWEET_HINTS)\n"
      ],
      "id": "TUZJqTfKz-YA"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "_accept_recipe_for_mode",
        "id": "BiYx-R2mz-YA"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def _accept_recipe_for_mode(rec_ings: list[str],\n",
        "                            vegetarian: bool,\n",
        "                            required_tokens: set[str] | None = None,\n",
        "                            title: str = \"\") -> bool:\n",
        "    # Diet gate\n",
        "    if vegetarian and not _is_vegetarian(rec_ings):\n",
        "        return False\n",
        "\n",
        "    if not required_tokens:\n",
        "        return True\n",
        "\n",
        "    R = set(t for t in required_tokens if len(t) >= 2)\n",
        "    have = _tokset(rec_ings) | _tokset([title])\n",
        "\n",
        "    # If user asked for a protein, candidate must actually contain a protein\n",
        "    req_has_protein = any(t in PROTEIN_TOKENS for t in R)\n",
        "    rec_has_protein = any(t in PROTEIN_TOKENS for t in have)\n",
        "    if req_has_protein and not rec_has_protein:\n",
        "        return False\n",
        "\n",
        "    # Minimal coverage: at least 60% of required tokens must be present\n",
        "    covered = len(R & have)\n",
        "    need = max(1, int(0.6 * len(R)))\n",
        "    if covered < need:\n",
        "        return False\n",
        "\n",
        "    # If protein requested but the recipe looks like a dessert, reject\n",
        "    if req_has_protein and _looks_sweet(title, rec_ings):\n",
        "        return False\n",
        "\n",
        "    return True\n"
      ],
      "id": "BiYx-R2mz-YA"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "_style_cycle_for",
        "id": "MWiLcSg7z-YA"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def _style_cycle_for(tokens_low: set[str]) -> list[str]:\n",
        "    has_pasta = any(t in tokens_low for t in [\"pasta\",\"spaghetti\",\"penne\",\"tagliatelle\"])\n",
        "    has_rice  = any(t in tokens_low for t in [\"rice\",\"basmati\",\"jasmine\",\"risotto\"])\n",
        "    base = [\"grill\",\"skillet\",\"curry\",\"tray bake\",\"one-pot pasta\",\"pilaf\",\"stir fry\",\"soup\",\"salad\"]\n",
        "    if has_pasta and \"one-pot pasta\" in base:\n",
        "        base.remove(\"one-pot pasta\"); base.insert(0,\"one-pot pasta\")\n",
        "    if has_rice and \"pilaf\" in base:\n",
        "        base.remove(\"pilaf\"); base.insert(0,\"pilaf\")\n",
        "    return base\n"
      ],
      "id": "MWiLcSg7z-YA"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "_inject_required_ingredients",
        "id": "upvHZebQz-YA"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def _inject_required_ingredients(rec: dict, required_tokens: set[str]) -> dict:\n",
        "    \"\"\"\n",
        "    Strict-vegetarian mode:\n",
        "    Ensure all required tokens appear in the ingredient list using canonical\n",
        "    plant-based forms. Handles all dairy categories (milk, yogurt, butter,\n",
        "    cheese, cream, ice cream), collapses stock tokens into 'vegetable stock',\n",
        "    and maps gelatin to agar agar.\n",
        "    \"\"\"\n",
        "    rec = dict(rec)\n",
        "    if st.session_state.get(\"diet\") != \"Vegetarian\":\n",
        "        return rec\n",
        "\n",
        "    # Current canonical tokens present\n",
        "    have_tokens = _tokset(rec.get(\"ingredients\", []))\n",
        "\n",
        "    # Missing tokens (canonical)\n",
        "    missing = [t for t in sorted(required_tokens) if t not in have_tokens]\n",
        "\n",
        "    # Canonical dairy ‚Üí plant-based equivalents\n",
        "    DAIRY_CANON = {\n",
        "        \"milk\":       \"soy milk\",\n",
        "        \"yogurt\":     \"soy yogurt\",\n",
        "        \"yoghurt\":    \"soy yogurt\",\n",
        "        \"butter\":     \"soy butter\",\n",
        "        \"cheese\":     \"soy cheese\",\n",
        "        \"cream\":      \"soy cream\",\n",
        "        \"ice\":        None,          # handled below (with 'ice cream')\n",
        "        \"icecream\":   \"soy ice cream\",\n",
        "        \"ice_cream\":  \"soy ice cream\",\n",
        "    }\n",
        "\n",
        "    # Additional explicit mappings\n",
        "    EXTRA_CANON = {\n",
        "        \"gelatin\": \"agar agar\",\n",
        "    }\n",
        "\n",
        "    # Helper: check if phrase is already in ingredient list\n",
        "    def _has_phrase(phrase: str) -> bool:\n",
        "        p = phrase.lower()\n",
        "        for it in rec.get(\"ingredients\", []):\n",
        "            if p in str(it).lower():\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    add_phrases: set[str] = set()\n",
        "\n",
        "    # --- 1) Dairy injections ---\n",
        "    for dairy_word, plant_equiv in DAIRY_CANON.items():\n",
        "        if dairy_word in missing:\n",
        "            # Handle ice cream explicitly\n",
        "            if dairy_word in {\"ice\", \"icecream\", \"ice_cream\"}:\n",
        "                if not _has_phrase(\"soy ice cream\"):\n",
        "                    add_phrases.add(\"soy ice cream\")\n",
        "                continue\n",
        "\n",
        "            if plant_equiv is None:\n",
        "                continue  # ignore bare \"ice\" or unhandled patterns\n",
        "\n",
        "            if not _has_phrase(plant_equiv):\n",
        "                add_phrases.add(plant_equiv)\n",
        "\n",
        "    # --- 2) Gelatin ‚Üí Agar agar ---\n",
        "    for k, v in EXTRA_CANON.items():\n",
        "        if k in missing and not _has_phrase(v):\n",
        "            add_phrases.add(v)\n",
        "\n",
        "    # --- 3) Stock tokens ‚Üí vegetable stock ---\n",
        "    if \"stock\" in missing or \"vegetable\" in missing:\n",
        "        if not _has_phrase(\"vegetable stock\"):\n",
        "            add_phrases.add(\"vegetable stock\")\n",
        "\n",
        "    # --- 4) Avoid injecting lone plant markers ---\n",
        "    bare_block = {\"soy\", \"almond\", \"oat\", \"coconut\", \"vegan\", \"plant\"}\n",
        "\n",
        "    # Inject non-dairy, non-stock tokens\n",
        "    for t in missing:\n",
        "        if t in DAIRY_CANON:  # handled\n",
        "            continue\n",
        "        if t in EXTRA_CANON:\n",
        "            continue\n",
        "        if t in {\"vegetable\", \"stock\"}:\n",
        "            continue\n",
        "        if t in bare_block:\n",
        "            continue\n",
        "        if not _has_phrase(t):\n",
        "            add_phrases.add(t)\n",
        "\n",
        "    # --- 5) Write back injections ---\n",
        "    if add_phrases:\n",
        "        rec[\"ingredients\"] = list(rec.get(\"ingredients\", [])) + sorted(add_phrases)\n",
        "\n",
        "        # Patch steps for clarity\n",
        "        steps = list(rec.get(\"steps\", []))\n",
        "        patch = \"Ensure you add the required items now: \" + \", \".join(sorted(add_phrases)) + \".\"\n",
        "        insert_at = 2 if len(steps) >= 2 else 1\n",
        "        steps.insert(insert_at, patch)\n",
        "        rec[\"steps\"] = steps\n",
        "\n",
        "    return rec\n",
        "\n",
        "\n",
        "# ======================= NEW: deterministic fresh 3 =====================\n"
      ],
      "id": "upvHZebQz-YA"
    },
    {
      "cell_type": "code",
      "metadata": {
        "name": "retrieve_strict_top3",
        "id": "ZZeoHk1ez-YA"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def retrieve_strict_top3(ings: list[str], cuisines: list[str], vegetarian: bool, salt: str) -> list[dict]:\n",
        "    \"\"\"\n",
        "    Assemble a diversified pool (local index + external APIs), enforce required-token\n",
        "    coverage and vegetarian rules, synthesize steps/images as needed, and return\n",
        "    TOPK distinct recipes (distinct by title+steps).\n",
        "    \"\"\"\n",
        "    import hashlib, random  # local-only deps\n",
        "\n",
        "    TOPK_LOCAL = int(globals().get(\"TOPK\", 3))\n",
        "    salted = salt or \"seed\"\n",
        "\n",
        "    # --- Local distinct selector (title+steps signatures) ----------------------\n",
        "    def _norm_local(s: str) -> str:\n",
        "        return (s or \"\").strip().lower()\n",
        "\n",
        "    def _distinct_topk_force_local(cands: list[dict], topk: int) -> list[dict]:\n",
        "        # rank by score (desc), then greedily keep first unseen (title+steps)\n",
        "        cands = sorted(cands, key=lambda z: float(z.get(\"score\", 0.0)), reverse=True)\n",
        "        seen_title: set[str] = set()\n",
        "        seen_steps: set[str] = set()\n",
        "        out: list[dict] = []\n",
        "        for r in cands:\n",
        "            title_norm = _norm_local(r.get(\"title\", \"\"))\n",
        "            steps_norm = \"\\n\".join(_norm_local(s) for s in r.get(\"steps\", []) if isinstance(s, str))[:4096]\n",
        "            tkey = hashlib.sha1(title_norm.encode(\"utf-8\")).hexdigest()\n",
        "            skey = hashlib.sha1(steps_norm.encode(\"utf-8\")).hexdigest()\n",
        "            if tkey in seen_title or skey in seen_steps:\n",
        "                continue\n",
        "            r.setdefault(\"image\", \"\")\n",
        "            r.setdefault(\"ingredients\", [])\n",
        "            r.setdefault(\"steps\", [])\n",
        "            seen_title.add(tkey)\n",
        "            seen_steps.add(skey)\n",
        "            out.append(r)\n",
        "            if len(out) == topk:\n",
        "                break\n",
        "        return out\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    # --- Protein intent expansion (non-veg only) ------------------------------\n",
        "    LAND_SET = {\n",
        "        \"meat\", \"red meat\", \"white meat\",\n",
        "        \"chicken\", \"chicken breast\", \"chicken thigh\", \"drumstick\", \"wings\", \"ground chicken\", \"minced chicken\",\n",
        "        \"beef\", \"steak\", \"ribeye\", \"sirloin\", \"tenderloin\", \"ground beef\", \"minced beef\", \"roast beef\",\n",
        "        \"lamb\", \"mutton\", \"ground lamb\", \"minced lamb\",\n",
        "        \"goat\", \"chevon\",\n",
        "        \"pork\", \"bacon\", \"ham\", \"prosciutto\", \"pancetta\", \"sausage\",\n",
        "        \"veal\",\n",
        "        \"turkey\", \"ground turkey\", \"turkey breast\",\n",
        "        \"duck\", \"duck breast\", \"duck leg\"\n",
        "    }\n",
        "    SEAFOOD_SET = {\n",
        "        \"seafood\", \"fish\",\n",
        "        \"salmon\", \"tuna\", \"cod\", \"haddock\", \"sea bass\", \"tilapia\", \"halibut\", \"trout\", \"mackerel\",\n",
        "        \"shrimp\", \"prawn\", \"prawns\", \"scallop\", \"scallops\",\n",
        "        \"mussel\", \"mussels\", \"clam\", \"clams\", \"octopus\", \"squid\", \"calamari\",\n",
        "        \"crab\", \"lobster\", \"anchovy\", \"anchovies\", \"sardine\", \"sardines\"\n",
        "    }\n",
        "    PROTEIN_TOKENS_LOCAL = LAND_SET | SEAFOOD_SET\n",
        "\n",
        "    MEAT_SYNONYMS    = {\"meat\", \"red meat\", \"white meat\"}\n",
        "    SEAFOOD_SYNONYMS = {\"seafood\", \"fish\", \"fishes\", \"fish meat\", \"white fish\", \"shellfish\"}\n",
        "    CHICKEN_SYNS     = {\"chicken\", \"chicken meat\", \"chicken breast\", \"chicken thigh\", \"drumstick\", \"wings\", \"ground chicken\", \"minced chicken\"}\n",
        "    BEEF_SYNS        = {\"beef\", \"steak\", \"ribeye\", \"sirloin\", \"tenderloin\", \"ground beef\", \"minced beef\", \"roast beef\"}\n",
        "    LAMB_SYNS        = {\"lamb\", \"mutton\", \"ground lamb\", \"minced lamb\"}\n",
        "    GOAT_SYNS        = {\"goat\", \"chevon\"}\n",
        "    PORK_SYNS        = {\"pork\", \"bacon\", \"ham\", \"prosciutto\", \"pancetta\", \"sausage\"}\n",
        "    VEAL_SYNS        = {\"veal\"}\n",
        "    TURKEY_SYNS      = {\"turkey\", \"turkey meat\", \"ground turkey\", \"turkey breast\"}\n",
        "    DUCK_SYNS        = {\"duck\", \"duck breast\", \"duck leg\"}\n",
        "\n",
        "    def _norm_token(s: str) -> str:\n",
        "        s = (s or \"\").strip().lower()\n",
        "        if s == \"lamp\":  # common typo\n",
        "            return \"lamb\"\n",
        "        return s\n",
        "\n",
        "    def _has_any(blob: str, syns: set[str]) -> bool:\n",
        "        return any(k in blob for k in syns)\n",
        "\n",
        "    def _expand_requested_proteins(req_proteins: set[str], user_ings: list[str]) -> set[str]:\n",
        "        corpus = [*user_ings, *list(req_proteins)]\n",
        "        blob = \" \".join(_norm_token(x) for x in corpus)\n",
        "        out = set(_norm_token(x) for x in req_proteins if x)\n",
        "\n",
        "        # generic\n",
        "        if _has_any(blob, MEAT_SYNONYMS):     out |= LAND_SET\n",
        "        if _has_any(blob, SEAFOOD_SYNONYMS):  out |= SEAFOOD_SET\n",
        "\n",
        "        # specific land families\n",
        "        if _has_any(blob, CHICKEN_SYNS):  out |= CHICKEN_SYNS\n",
        "        if _has_any(blob, BEEF_SYNS):     out |= BEEF_SYNS\n",
        "        if _has_any(blob, LAMB_SYNS):     out |= LAMB_SYNS\n",
        "        if _has_any(blob, GOAT_SYNS):     out |= GOAT_SYNS\n",
        "        if _has_any(blob, PORK_SYNS):     out |= PORK_SYNS\n",
        "        if _has_any(blob, VEAL_SYNS):     out |= VEAL_SYNS\n",
        "        if _has_any(blob, TURKEY_SYNS):   out |= TURKEY_SYNS\n",
        "        if _has_any(blob, DUCK_SYNS):     out |= DUCK_SYNS\n",
        "\n",
        "        # literal group tokens\n",
        "        if any(t in out for t in {\"meat\", \"red meat\", \"white meat\"}): out |= LAND_SET\n",
        "        if any(t in out for t in {\"seafood\", \"fish\"}):                out |= SEAFOOD_SET\n",
        "        return out\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    # 1) Required tokens (veg-stripped if needed) + record what was dropped\n",
        "    req_tokens, dropped, req_proteins = _required_tokens_for_mode(ings, vegetarian)\n",
        "    st.session_state[\"veg_dropped\"] = dropped if vegetarian else set()\n",
        "    pool: list[dict] = []\n",
        "\n",
        "    # Expanded protein intents (non-veg only)\n",
        "    req_proteins_expanded: set[str] = set()\n",
        "    if not vegetarian:\n",
        "        req_proteins_expanded = _expand_requested_proteins(req_proteins, ings)\n",
        "\n",
        "    # 2) Local results first (bigger pool ‚Üí better diversity)\n",
        "    if LOCAL_INDEX.ok:\n",
        "        query_local = list(req_tokens) if vegetarian else ings\n",
        "        for r in LOCAL_INDEX.search(query_local, k=220):\n",
        "            if not _accept_recipe_for_mode(\n",
        "                r.get(\"ingredients\", []),\n",
        "                vegetarian,\n",
        "                required_tokens=req_tokens,\n",
        "                title=r.get(\"title\", \"\")\n",
        "            ):\n",
        "                continue\n",
        "            rr = dict(r)\n",
        "            rr[\"score\"] = 0.64 + 0.36 * float(r.get(\"score\", 0.0))\n",
        "            pool.append(rr)\n",
        "\n",
        "    # 3) External APIs (veg uses veg-stripped terms)\n",
        "    query_terms = list(req_tokens) if vegetarian else ings\n",
        "    pool += fetch_spoonacular(query_terms, n=36, vegetarian=vegetarian)\n",
        "    pool += fetch_mealdb(query_terms,     n=30, vegetarian=vegetarian)\n",
        "    if not vegetarian:\n",
        "        pool += fetch_mealdb_seafood(n=30)\n",
        "\n",
        "    # 4) Resolve images + synthesize steps if missing\n",
        "    tokens_low  = _tokset(query_terms)\n",
        "    styles_pref = _style_cycle_for(tokens_low)\n",
        "    seen_imgs: set[str] = set()\n",
        "\n",
        "    new_pool: list[dict] = []\n",
        "    for idx, r in enumerate(pool):\n",
        "        rr = dict(r)  # work on a copy\n",
        "\n",
        "        # ---- STRICT VEGETARIAN PATCH: dairy/stock ‚Üí plant, with UI note\n",
        "        if vegetarian:\n",
        "            rr = _apply_veg_substitutions_recipe(rr, salted)\n",
        "            rr, swapped = _veg_milk_swap_in_recipe(rr)\n",
        "            rr = _normalize_veg_dairy_terms(rr)\n",
        "            if swapped:\n",
        "                prev = st.session_state.get(\"veg_dropped\", set())\n",
        "                st.session_state[\"veg_dropped\"] = prev | {f\"{s} ‚Üí soy/veg-alt\" for s in swapped}\n",
        "\n",
        "        # ---- NON-VEG: honor expanded protein intents\n",
        "        if not vegetarian and req_proteins_expanded:\n",
        "            have = _tokset(rr.get(\"ingredients\", [])) | _tokset([rr.get(\"title\", \"\")])\n",
        "            if not any(p in have for p in req_proteins_expanded):\n",
        "                continue  # skip this candidate\n",
        "\n",
        "        # ---- Image resolve/refresh (salted for diversity)\n",
        "        rr[\"image\"] = _resolve_image(\n",
        "            rr.get(\"image\"),\n",
        "            vegetarian,\n",
        "            rr.get(\"title\", \"\"),\n",
        "            f\"{salted}#{idx}\",\n",
        "            seen_imgs\n",
        "        )\n",
        "\n",
        "        # ---- Fill steps when absent (deterministic but varied per candidate)\n",
        "        if not rr.get(\"steps\"):\n",
        "            style = styles_pref[idx % len(styles_pref)] if styles_pref else \"skillet\"\n",
        "            rr[\"steps\"] = distinct_steps_from_ingredients(\n",
        "                rr.get(\"title\", \"\"),\n",
        "                rr.get(\"ingredients\", []),\n",
        "                style=style,\n",
        "                seed=1000 + idx,\n",
        "                required_tokens=req_tokens\n",
        "            )\n",
        "\n",
        "        # ---- Non-veg boost when an actual protein exists (except eggs)\n",
        "        if not vegetarian:\n",
        "            have = _tokset(rr.get(\"ingredients\", [])) | _tokset([rr.get(\"title\", \"\")])\n",
        "            if any(t in PROTEIN_TOKENS_LOCAL for t in have if t not in {\"egg\", \"eggs\"}):\n",
        "                rr[\"score\"] = float(rr.get(\"score\", 0.0)) + 0.20\n",
        "\n",
        "        new_pool.append(rr)\n",
        "\n",
        "    # replace pool with filtered/enhanced candidates\n",
        "    pool = new_pool\n",
        "\n",
        "    # 5) Enforce required tokens into every candidate\n",
        "    pool = [_inject_required_ingredients(r, req_tokens) for r in pool]\n",
        "\n",
        "    # 6) Hard vegetarian guard immediately before ranking\n",
        "    if vegetarian:\n",
        "        pool = [r for r in pool if _is_vegetarian(r.get(\"ingredients\", []))]\n",
        "\n",
        "    # 7) Select distinct top-k (by title+steps)\n",
        "    uniq = _distinct_topk_force_local(pool, TOPK_LOCAL)\n",
        "\n",
        "    # 8) If fewer than TOPK, synthesize DISTINCT fallbacks (salted ‚Üí per-search variety)\n",
        "    if len(uniq) < TOPK_LOCAL:\n",
        "        rng = random.Random(int(hashlib.sha1((\"syn\" + salted).encode()).hexdigest(), 16))\n",
        "\n",
        "        veg_templates = [\n",
        "            (\"One-Pot Pasta Primavera\", [\"olive oil\",\"garlic\",\"tomato\",\"basil\",\"pasta\",\"spinach\",\"nut parmesan\"], \"one-pot pasta\"),\n",
        "            (\"Chickpea & Spinach Curry\", [\"oil\",\"onion\",\"garlic\",\"ginger\",\"chickpeas\",\"tomato\",\"curry powder\",\"soy yogurt\"], \"curry\"),\n",
        "            (\"Mediterranean Orzo Salad\", [\"orzo\",\"olive oil\",\"lemon\",\"tomato\",\"cucumber\",\"vegan feta\",\"olive\",\"parsley\"], \"salad\"),\n",
        "            (\"Mushroom Barley Soup\", [\"olive oil\",\"onion\",\"garlic\",\"mushroom\",\"barley\",\"thyme\",\"vegetable stock\"], \"soup\"),\n",
        "            (\"Tofu Stir-Fry\", [\"tofu\",\"soy sauce\",\"ginger\",\"garlic\",\"broccoli\",\"bell pepper\",\"sesame oil\"], \"stir fry\"),\n",
        "            (\"Tray-Bake Veg Medley\", [\"olive oil\",\"broccoli\",\"cauliflower\",\"potato\",\"paprika\",\"lemon\"], \"tray bake\"),\n",
        "            (\"Lentil Pilaf\", [\"olive oil\",\"onion\",\"garlic\",\"brown lentils\",\"rice\",\"cumin\",\"bay leaf\"], \"pilaf\"),\n",
        "            (\"Grilled Tofu & Veg Skewers\", [\"marinated firm tofu\",\"zucchini\",\"bell pepper\",\"red onion\",\"olive oil\",\"lemon\",\"oregano\"], \"grill\"),\n",
        "            (\"Smoky Eggplant Kebab\", [\"eggplant\",\"olive oil\",\"garlic\",\"lemon\",\"parsley\",\"sumac\",\"flatbread\"], \"grill\"),\n",
        "            (\"Tandoori Tofu Tikka\", [\"tofu (pressed)\",\"soy yogurt\",\"garam masala\",\"ginger\",\"garlic\",\"lemon\"], \"grill\"),\n",
        "        ]\n",
        "\n",
        "        nonveg_templates = [\n",
        "            (\"Chicken Tomato Skillet\", [\"olive oil\",\"garlic\",\"onion\",\"chicken breast\",\"tomato\",\"basil\"], \"skillet\"),\n",
        "            (\"Beef Pilaf\", [\"oil\",\"onion\",\"garlic\",\"ground beef\",\"rice\",\"bay leaf\",\"parsley\"], \"pilaf\"),\n",
        "            (\"Seafood Curry\", [\"oil\",\"onion\",\"garlic\",\"ginger\",\"shrimp\",\"curry powder\",\"coconut milk\",\"rice\"], \"curry\"),\n",
        "            (\"Lemon Herb Baked Salmon\", [\"salmon\",\"olive oil\",\"lemon\",\"garlic\",\"parsley\"], \"tray bake\"),\n",
        "            (\"Turkey Noodle Soup\", [\"turkey\",\"noodle\",\"carrot\",\"celery\",\"onion\",\"stock\"], \"soup\"),\n",
        "            (\"Prawn Stir-Fry\", [\"shrimp\",\"soy sauce\",\"ginger\",\"garlic\",\"snap peas\",\"sesame oil\"], \"stir fry\"),\n",
        "            (\"Beef & Veggie Ragu\", [\"olive oil\",\"onion\",\"garlic\",\"ground beef\",\"tomato\",\"oregano\",\"pasta\"], \"one-pot pasta\"),\n",
        "            (\"Chicken Shish Kebab\", [\"chicken thigh\",\"olive oil\",\"garlic\",\"lemon\",\"paprika\",\"oregano\",\"red onion\"], \"grill\"),\n",
        "            (\"Adana Kebab (Turkish)\", [\"ground beef\",\"ground lamb\",\"red pepper flakes\",\"sumac\",\"parsley\",\"flatbread\"], \"grill\"),\n",
        "            (\"Tandoori Chicken\", [\"chicken\",\"yogurt\",\"tandoori masala\",\"ginger\",\"garlic\",\"lemon\"], \"grill\"),\n",
        "            (\"Grilled Salmon with Dill\", [\"salmon\",\"olive oil\",\"lemon\",\"dill\",\"garlic\"], \"grill\"),\n",
        "        ]\n",
        "        T = veg_templates if vegetarian else nonveg_templates\n",
        "        req_tokens_list = list(req_tokens)\n",
        "\n",
        "        seen_fallback_imgs: set[str] = set()\n",
        "        for idx in range(40):\n",
        "            name, base_ings, style = rng.choice(T)\n",
        "            chosen = list(base_ings)\n",
        "\n",
        "            # inject required tokens deterministically but varied\n",
        "            for tok in sorted(req_tokens_list):\n",
        "                if tok not in _tokset(chosen):\n",
        "                    chosen.insert(1 + (idx % 2), tok)\n",
        "\n",
        "            title = f\"{name} with {_best3(ings)}\" if ings else name\n",
        "            steps = distinct_steps_from_ingredients(\n",
        "                title, chosen, style=style, seed=300 + idx + len(uniq), required_tokens=req_tokens\n",
        "            )\n",
        "\n",
        "            # salted fallback image to keep results unique even without APIs\n",
        "            img = _pexels_image(f\"{title} plated recipe\", per_page=14, page=1 + (idx % 3))\n",
        "            if not img:\n",
        "                img = _fallback_food_image(vegetarian, title, f\"{salted}|{idx}\", seen_fallback_imgs)\n",
        "            if img in seen_fallback_imgs:\n",
        "                img = _fallback_food_image(vegetarian, title + str(idx), f\"{salted}|{idx*7}\", seen_fallback_imgs)\n",
        "            seen_fallback_imgs.add(img)\n",
        "\n",
        "            uniq.append({\n",
        "                \"title\": title,\n",
        "                \"image\": img,\n",
        "                \"ingredients\": chosen,\n",
        "                \"steps\": steps,\n",
        "                \"source\": \"synthetic\",\n",
        "                \"score\": 0.20 - 0.001 * idx\n",
        "            })\n",
        "            uniq = _distinct_topk_force_local(uniq, TOPK_LOCAL)\n",
        "            if len(uniq) == TOPK_LOCAL:\n",
        "                break\n",
        "\n",
        "    # 9) Final pass: ensure one unique image per recipe and enforce tokens again\n",
        "    out: list[dict] = []\n",
        "    seen_final: set[str] = set()\n",
        "    for j, r in enumerate(uniq[:TOPK_LOCAL]):\n",
        "        if vegetarian and not _is_vegetarian(r.get(\"ingredients\", [])):  # safety\n",
        "            continue\n",
        "        r[\"image\"] = _resolve_image(\n",
        "            r.get(\"image\"),\n",
        "            vegetarian,\n",
        "            r.get(\"title\", \"\"),\n",
        "            f\"{salted}::final{j}\",\n",
        "            seen_final\n",
        "        )\n",
        "        out.append(_inject_required_ingredients(r, req_tokens))\n",
        "\n",
        "    return out[:TOPK_LOCAL]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# =====================================================================\n",
        "# UI\n",
        "# =====================================================================\n",
        "left, right = st.columns([1.55, 1.0])\n",
        "\n",
        "with left:\n",
        "    st.subheader(\"Ingredients\")\n",
        "    demo = \"tomato, basil, garlic, olive oil\"\n",
        "    st.session_state[\"diet\"] = st.radio(\"Diet\", [\"Non-vegetarian\",\"Vegetarian\"], horizontal=True, index=0, key=\"diet_radio\")\n",
        "    st.text_area(\"Comma-separated or one per line\", value=demo, height=120,\n",
        "                 placeholder=\"e.g., tomato, basil, garlic, olive oil\", key=\"ing_text\")\n",
        "\n",
        "    if st.button(\"Search recipes\", type=\"primary\", key=\"btn_search\"):\n",
        "        ings, sig = _canon_ings(st.session_state.get(\"ing_text\",\"\"))\n",
        "        if not ings:\n",
        "            st.warning(\"Please provide at least one ingredient.\");\n",
        "            st.stop()\n",
        "\n",
        "        # --- NEW: swap dairy milk -> soy/almond in Vegetarian mode BEFORE prediction/search ---\n",
        "        veg_now = (st.session_state[\"diet\"] == \"Vegetarian\")\n",
        "        if veg_now:\n",
        "            ings, _swapped = _veg_milk_swap(ings)\n",
        "            if _swapped:\n",
        "                prev = st.session_state.get(\"veg_dropped\", set())\n",
        "                note = {f\"{s} ‚Üí soy/almond milk\" for s in _swapped}\n",
        "                st.session_state[\"veg_dropped\"] = set(prev) | note\n",
        "        # -------------------------------------------------------------------\n",
        "\n",
        "        cuisines, probs = predict_topk(pipe, INV, ings, k=TOPK)\n",
        "        meta = {c: {\"title\": f\"{c.title()}-Style\"} for c in cuisines}\n",
        "\n",
        "        is_veg = (st.session_state[\"diet\"] == \"Vegetarian\")\n",
        "        # salt ensures different photos/recipes across searches even with similar input\n",
        "        salt = uuid.uuid4().hex[:8] + \"|\" + str(int(time.time()))\n",
        "        recs = retrieve_strict_top3(ings, cuisines, vegetarian=is_veg, salt=salt)\n",
        "\n",
        "        # map titles -> ingredients for planner macros\n",
        "        title_to_ings = {r[\"title\"]: r[\"ingredients\"] for r in recs}\n",
        "\n",
        "        st.session_state.update({\n",
        "            \"pred_ready\": True,\n",
        "            \"df_pred\": pd.DataFrame({\"cuisine\": cuisines, \"probability\": probs}),\n",
        "            \"cuisines\": cuisines, \"meta\": meta, \"selected\": cuisines[0] if cuisines else None,\n",
        "            \"ings\": ings, \"last_sig\": sig, \"recs_top3\": recs, \"search_salt\": salt,\n",
        "            \"title_to_ings\": title_to_ings,\n",
        "            \"podcast_context\": {\"title\": recs[0][\"title\"] if recs else \"\",\n",
        "                                \"ingredients\": recs[0][\"ingredients\"] if recs else [],\n",
        "                                \"steps\": recs[0][\"steps\"] if recs else []}\n",
        "        })\n",
        "        st.rerun()\n",
        "\n",
        "\n",
        "with left:\n",
        "    if st.session_state[\"pred_ready\"] == True:\n",
        "        df_pred  = st.session_state[\"df_pred\"]\n",
        "        diet_now = st.session_state[\"diet\"]\n",
        "        salt_key = st.session_state.get(\"search_salt\",\"\")\n",
        "\n",
        "        tab_pred, tab_pod, tab_plan = st.tabs([\"üîÆ Predictions\", \"üéôÔ∏è Podcast\", \"üìÖ Planner\"])\n",
        "\n",
        "        # -------------------- Predictions --------------------\n",
        "        with tab_pred:\n",
        "            st.markdown(f\"### Top predictions ¬∑ **{diet_now}**\")\n",
        "            if not df_pred.empty:\n",
        "                st.plotly_chart(\n",
        "                    bar_colored(df_pred[\"cuisine\"], df_pred[\"probability\"], title_y=\"Probability\", height=180),\n",
        "                    use_container_width=True, config={\"displayModeBar\": False}, key=f\"pred_chart_{salt_key}\"\n",
        "                )\n",
        "            if diet_now == \"Vegetarian\":\n",
        "                dropped = st.session_state.get(\"veg_dropped\", set())\n",
        "                if dropped:\n",
        "                    st.info(\"Removed for strict-veg: \" + \", \".join(sorted(set(dropped))))\n",
        "\n",
        "            # Icons (avoid f-strings with backslashes)\n",
        "            icon_veg = \"\"\n",
        "            if ICON_VEG.exists():  icon_veg = \"![](\" + str(ICON_VEG).replace(\"\\\\\",\"/\") + \")\"\n",
        "            icon_non = \"\"\n",
        "            if ICON_NONV.exists(): icon_non = \"![](\" + str(ICON_NONV).replace(\"\\\\\",\"/\") + \")\"\n",
        "\n",
        "            st.markdown(\"### Recommended recipes (unique per search)\")\n",
        "            recs = st.session_state.get(\"recs_top3\", [])\n",
        "            for i, rec in enumerate(recs, 1):\n",
        "                badge = f\"{icon_veg} \" if diet_now==\"Vegetarian\" else f\"{icon_non} \"\n",
        "                st.markdown(f'<div class=\"pill\">{badge}{rec[\"title\"]}  <span class=\"caption\">source: {rec.get(\"source\",\"\")}</span></div>',\n",
        "                            unsafe_allow_html=True)\n",
        "                st.image(rec[\"image\"], width=380)  # explicit width -> no use_column_width warning\n",
        "\n",
        "                with st.expander(\"Ingredients\", expanded=False):\n",
        "                    st.write(\"\\n\".join(f\"- {x}\" for x in rec[\"ingredients\"]))\n",
        "                with st.expander(\"Steps\", expanded=True):\n",
        "                    st.write(\"\\n\".join(f\"{k+1}. {s}\" for k, s in enumerate(rec[\"steps\"])))\n",
        "\n",
        "                m = macro_totals(rec[\"ingredients\"])\n",
        "                st.plotly_chart(\n",
        "                    bar_colored([\"Calories (kcal)\",\"Protein (g)\",\"Fat (g)\",\"Carbs (g)\"],\n",
        "                                [m[\"kcal\"], m[\"protein\"], m[\"fat\"], m[\"carbs\"]], title_y=\"Amount\"),\n",
        "                    use_container_width=True, config={\"displayModeBar\": False}, key=f\"macro_{i}_{salt_key}\"\n",
        "                )\n",
        "\n",
        "                # PDF (language choice is for the PDF text only; UI stays English)\n",
        "                col_pdf, col_lang, col_v, col_s, col_btn = st.columns([1,1,1,1,1])\n",
        "                with col_pdf:\n",
        "                    if PDF_OK:\n",
        "                        st.caption(\" \")\n",
        "                with col_lang:\n",
        "                    lang_ui = st.selectbox(f\"Speech language #{i}\", list(LANGUAGE_CHOICES.keys()),\n",
        "                                           index=0, key=f\"lang_{i}\")\n",
        "                with col_v:\n",
        "                    default_idx = list(VOICE.keys()).index([\"Female-warm\",\"Male-soft\",\"Male-deep\"][(i-1)%3])\n",
        "                    preset = st.selectbox(f\"Voice preset #{i}\", list(VOICE.keys()),\n",
        "                                          index=default_idx, key=f\"voice_{i}\")\n",
        "                with col_s:\n",
        "                    spd = st.slider(f\"Speed #{i}\", min_value=0.85, max_value=1.20,\n",
        "                                    value=float(VOICE[preset][\"speed\"]), step=0.01, key=f\"speed_{i}\")\n",
        "                with col_btn:\n",
        "                    if st.button(\"üéß Instruction Voice\", key=f\"audio_{i}\", use_container_width=True):\n",
        "                        code = LANGUAGE_CHOICES[lang_ui]\n",
        "                        # Do not mutate displayed steps; translate a copy only for audio\n",
        "                        lines_src = [f\"Today's dish is: {rec['title']}.\", \"Here are the instructions.\"] + \\\n",
        "                                [f\"Step {k+1}: {s}\" for k, s in enumerate(rec[\"steps\"])]\n",
        "                        lines = translate_if(lines_src, code)\n",
        "                        audio = tts_instructions(lines, code, VOICE[preset], spd)\n",
        "                        if audio:\n",
        "                            st.audio(audio, format=\"audio/mp3\")\n",
        "                            st.download_button(\"‚¨á MP3\", audio,\n",
        "                                               file_name=f\"{i}_{LANGUAGE_CHOICES[lang_ui]}_instruction.mp3\",\n",
        "                                               mime=\"audio/mpeg\", use_container_width=True, key=f\"mp3_{i}\")\n",
        "\n",
        "                # PDF download (translated or not, but source data unchanged)\n",
        "                code = LANGUAGE_CHOICES[lang_ui]\n",
        "                pdf_text_lines = [f\"{k+1}. {s}\" for k, s in enumerate(rec[\"steps\"])]\n",
        "                pdf_lines = translate_if(pdf_text_lines, LANGUAGE_CHOICES[lang_ui])\n",
        "                pdfb = recipe_pdf(rec[\"title\"], rec[\"ingredients\"], \"\\n\".join(pdf_lines), m, rec.get(\"image\",\"\"))\n",
        "                if pdfb:\n",
        "                    safe = re.sub(r\"[^a-zA-Z0-9]+\",\"_\",rec[\"title\"]).lower()\n",
        "                    st.download_button(\"üìÑ Download PDF\", data=pdfb, file_name=f\"{safe}.pdf\",\n",
        "                                       mime=\"application/pdf\", use_container_width=True, key=f\"pdf_{i}_{salt_key}\")\n",
        "\n",
        "        # ------------------------ PODCAST ------------------------\n",
        "        with tab_pod:\n",
        "            st.caption(\"Interview-style podcast: Host ‚Üî Chef.\")\n",
        "            recs = st.session_state.get(\"recs_top3\", [])\n",
        "            opts = [f\"{i+1}) {r['title']}\" for i, r in enumerate(recs)]\n",
        "            pick = st.selectbox(\"Select recipe\", list(range(len(opts))),\n",
        "                                format_func=lambda i: opts[i], index=0 if opts else 0,\n",
        "                                key=f\"pod_pick_{salt_key}\") if opts else 0\n",
        "            sel = recs[pick] if recs else {\"title\":\"\",\"ingredients\":[],\"steps\":[]}\n",
        "            c1, c2 = st.columns(2)\n",
        "            with c1:\n",
        "                host = st.text_input(\"Host name\", value=\"Host\", key=f\"pod_host_{salt_key}\")\n",
        "                v_h  = st.selectbox(\"Host voice\", list(VOICE.keys()),\n",
        "                                    index=list(VOICE.keys()).index(\"Male-soft\"), key=f\"pod_vh_{salt_key}\")\n",
        "                s_h  = st.slider(\"Host speed\", 0.85, 1.20, float(VOICE[v_h][\"speed\"]), 0.01, key=f\"pod_sh_{salt_key}\")\n",
        "            with c2:\n",
        "                chef = st.text_input(\"Chef name\", value=\"Chef\", key=f\"pod_chef_{salt_key}\")\n",
        "                v_c  = st.selectbox(\"Chef voice\", list(VOICE.keys()),\n",
        "                                    index=list(VOICE.keys()).index(\"Male-deep\"), key=f\"pod_vc_{salt_key}\")\n",
        "                s_c  = st.slider(\"Chef speed\", 0.85, 1.20, float(VOICE[v_c][\"speed\"]), 0.01, key=f\"pod_sc_{salt_key}\")\n",
        "            lang_ui = st.selectbox(\"Podcast language\", list(LANGUAGE_CHOICES.keys()), index=0, key=f\"pod_lang_{salt_key}\")\n",
        "            code = LANGUAGE_CHOICES[lang_ui]\n",
        "            lines = translate_if(podcast_script(sel[\"title\"], sel[\"ingredients\"], sel[\"steps\"], host, chef), code)\n",
        "            st.text_area(\"Transcript (preview)\", \"\\n\".join(lines), height=180, key=f\"pod_tx_{salt_key}\")\n",
        "            colp1, colp2, _ = st.columns([1,1,1])\n",
        "            with colp1:\n",
        "                if st.button(\"üéôÔ∏è Generate Podcast MP3\", key=f\"pod_build_{salt_key}\"):\n",
        "                    audio = tts_podcast(lines, code, VOICE[v_h], VOICE[v_c], s_h, s_c)\n",
        "                    if audio:\n",
        "                        st.audio(audio, format=\"audio/mp3\")\n",
        "                        st.download_button(\"‚¨á Download Podcast MP3\", audio,\n",
        "                                           file_name=f\"podcast_{re.sub(r'[^a-zA-Z0-9]+','_',sel['title']).lower()}.mp3\",\n",
        "                                           mime=\"audio/mpeg\", use_container_width=True, key=f\"pod_dl_{salt_key}\")\n",
        "            with colp2:\n",
        "                code = LANGUAGE_CHOICES[lang_ui]\n",
        "                title_tr = translate_if([sel[\"title\"]], code)[0]\n",
        "                pdfp = podcast_pdf(title_tr, lines, lang_code=code)\n",
        "\n",
        "                if pdfp:\n",
        "                    st.download_button(\"üìÑ Download Transcript PDF\", pdfp,\n",
        "                                       file_name=f\"podcast_{re.sub(r'[^a-zA-Z0-9]+','_',sel['title']).lower()}_transcript.pdf\",\n",
        "                                       mime=\"application/pdf\", use_container_width=True, key=f\"pod_pdf_{salt_key}\")\n",
        "\n",
        "        # ------------------------ Planner ------------------------\n",
        "        with tab_plan:\n",
        "            st.caption(\"Weekly planner + charts.\")\n",
        "            mode = st.radio(\"Add mode\", [\"From top-3\",\"Custom\"], horizontal=True, key=f\"plan_mode_{salt_key}\")\n",
        "            if mode == \"From top-3\":\n",
        "                opts = [f\"{i+1}) {r['title']}\" for i, r in enumerate(st.session_state.get(\"recs_top3\", []))]\n",
        "                pick = st.selectbox(\"Pick recipe\", opts, index=0 if opts else None, key=f\"plan_pick_{salt_key}\")\n",
        "                dish = (st.session_state.get(\"recs_top3\", [])[int(pick.split(')')[0])-1][\"title\"]) if opts else \"\"\n",
        "            else:\n",
        "                dish = st.text_input(\"Recipe name (custom)\", value=\"\", key=f\"plan_custom_{salt_key}\")\n",
        "            days = [f\"Day {i}\" for i in range(1,8)]\n",
        "            cL, cR = st.columns([1,2])\n",
        "            with cL: dsel = st.selectbox(\"Day\", days, index=0, key=f\"plan_day_{salt_key}\")\n",
        "            with cR:\n",
        "                a,b,c = st.columns(3)\n",
        "                with a:\n",
        "                    if st.button(\"Add/Update\", use_container_width=True, key=f\"plan_add_{salt_key}\"):\n",
        "                        if dish.strip():\n",
        "                            found=False\n",
        "                            for r in st.session_state[\"meal_plan\"]:\n",
        "                                if r[\"Day\"]==dsel: r[\"Recipe\"]=dish.strip(); found=True; break\n",
        "                            if not found:\n",
        "                                nxt=(max([r[\"Order\"] for r in st.session_state[\"meal_plan\"]] or [0])+1)\n",
        "                                st.session_state[\"meal_plan\"].append({\"Order\":nxt,\"Day\":dsel,\"Recipe\":dish.strip()})\n",
        "                with b:\n",
        "                    if st.button(\"Delete day\", use_container_width=True, key=f\"plan_del_{salt_key}\"):\n",
        "                        st.session_state[\"meal_plan\"] = [r for r in st.session_state[\"meal_plan\"] if r[\"Day\"]!=dsel]\n",
        "                with c:\n",
        "                    if st.button(\"Clear all\", use_container_width=True, key=f\"plan_clear_{salt_key}\"):\n",
        "                        st.session_state[\"meal_plan\"] = []\n",
        "            if st.session_state[\"meal_plan\"]:\n",
        "                df = pd.DataFrame(st.session_state[\"meal_plan\"]).sort_values(\"Order\").reset_index(drop=True)\n",
        "                # compute macros from stored ingredients where available\n",
        "                t2i = st.session_state.get(\"title_to_ings\", {})\n",
        "                totals = []\n",
        "                for _, r in df.iterrows():\n",
        "                    ings_for = t2i.get(r[\"Recipe\"], [r[\"Recipe\"]])  # fallback uses name\n",
        "                    totals.append(macro_totals(ings_for))\n",
        "                mdf = pd.DataFrame(totals); df = pd.concat([df, mdf], axis=1)\n",
        "                st.dataframe(df, use_container_width=True, height=260)\n",
        "                st.plotly_chart(kcal_line(df[\"Day\"], df[\"kcal\"]),  use_container_width=True, config={\"displayModeBar\": False}, key=f\"kcal_fig_{salt_key}\")\n",
        "                st.plotly_chart(macros_stacked(df[\"Day\"], df[\"protein\"], df[\"fat\"], df[\"carbs\"]),\n",
        "                                use_container_width=True, config={\"displayModeBar\": False}, key=f\"mac_fig_{salt_key}\")\n",
        "                W = {\"kcal\":float(df[\"kcal\"].sum()),\"protein\":float(df[\"protein\"].sum()),\n",
        "                     \"fat\":float(df[\"fat\"].sum()),\"carbs\":float(df[\"carbs\"].sum())}\n",
        "                st.info(f\"Weekly totals ‚Äî kcal: {W['kcal']:.0f}, Protein: {W['protein']:.1f} g, Fat: {W['fat']:.1f} g, Carbs: {W['carbs']:.1f} g\")\n",
        "\n",
        "with right:\n",
        "    st.subheader(\"How to use\")\n",
        "    st.markdown(\n",
        "        \"\"\"\n",
        "        <ul class=\"howto\">\n",
        "          <li><b>Enter ingredients</b> ‚Äî comma-separated or one per line.</li>\n",
        "          <li><b>Select diet</b> ‚Äî Vegetarian strictly excludes meat, seafood, egg, gelatin and stock derivatives.</li>\n",
        "          <li>Click <b>Search recipes</b> ‚Äî every search returns <b>three new, distinct recipes</b> with\n",
        "              <b>unique images</b>. Veg mode uses only vegetarian candidates.</li>\n",
        "          <li>Open a recipe to review <b>ingredients</b> and <b>steps</b>; download a <b>PDF</b> or generate\n",
        "              <b>instruction audio</b> in your chosen language (on-screen text stays in English).</li>\n",
        "          <li>Use <b>Podcast</b> for a host ‚Üî chef dialogue with adjustable voices and speed.</li>\n",
        "          <li>Plan your week in <b>Planner</b>; macro totals and charts update automatically.</li>\n",
        "        </ul>\n",
        "        \"\"\",\n",
        "        unsafe_allow_html=True\n",
        "    )\n",
        "\n",
        "# =====================================================================\n",
        "# End of file\n",
        "# =====================================================================\n"
      ],
      "id": "ZZeoHk1ez-YA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conclusion\n",
        "\n",
        "Smart Recipe Finder (PRO) demonstrates how classical machine-learning methods, ingredient-level text analysis, and structured dietary logic can be combined to create an intelligent and practical recipe-recommendation system. By leveraging a pre-trained cuisine classification pipeline trained on the large-scale Kaggle Recipe Ingredients Dataset‚Äîcontaining more than 2 million ingredient entries and approximately 45,000 recipes‚Äîthe system transforms simple user-provided ingredient lists into meaningful culinary insights.\n",
        "\n",
        "Throughout this project, I implemented a complete end-to-end workflow: ingredient preprocessing, vegetarian rule enforcement, cuisine prediction using a TF‚ÄìIDF‚Äìbased linear model, nutritional estimation, and a suite of interactive Plotly visualizations. These components were integrated into a clean Streamlit interface while also being made compatible with Jupyter Notebook for documentation and analysis.\n",
        "\n",
        "The final application provides users with clear cuisine predictions, transparent ingredient transformations, and easy-to-interpret nutritional summaries. Its modular design‚Äîseparating preprocessing, prediction, visualization, and UI layers‚Äîensures maintainability and makes the system straightforward to extend.\n",
        "\n",
        "Potential future improvements include expanding the nutritional database, supporting additional dietary restrictions (such as gluten-free or low-carb profiles), incorporating multilingual ingredient recognition, and retraining the model using more diverse or updated recipe datasets. Overall, the project demonstrates the practical value of combining data science, machine learning, and interactive visualization tools to deliver a user-friendly and informative culinary decision-support system."
      ],
      "metadata": {
        "id": "Jlc2CDzU5X25"
      },
      "id": "Jlc2CDzU5X25"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.2",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}